{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in here: custom_input_file\n",
      "geo_file_path:../../test/input/florence_933020089/DOMAIN/Route_Link.nc\n",
      "creating supernetwork connections set\n",
      "{'title_string': 'Hurricante Florence cutout', 'geo_file_path': '../../test/input/florence_933020089/DOMAIN/Route_Link.nc', 'mask_file_path': '../../test/input/geo/Channels/masks/933020089_mask.csv', 'mask_layer_string': '', 'mask_driver_string': 'csv', 'mask_key': 0, 'columns': {'key': 'link', 'downstream': 'to', 'dx': 'Length', 'n': 'n', 'ncc': 'nCC', 's0': 'So', 'bw': 'BtmWdth', 'waterbody': 'NHDWaterbodyComID', 'tw': 'TopWdth', 'twcc': 'TopWdthCC', 'musk': 'MusK', 'musx': 'MusX', 'cs': 'ChSlp', 'alt': 'alt'}, 'waterbody_null_code': -9999, 'terminal_code': 0, 'driver_string': 'NetCDF', 'layer_string': 0}\n",
      "supernetwork connections set complete\n",
      "... in 0.20779967308044434 seconds.\n",
      "organizing connections into reaches ...\n",
      "reach organization complete\n",
      "... in 0.004337787628173828 seconds.\n",
      "setting channel initial states ...\n",
      "channel initial states complete\n",
      "... in 0.017256498336791992 seconds.\n",
      "creating qlateral array ...\n",
      "qlateral array complete\n",
      "... in 0.2760281562805176 seconds.\n",
      "executing routing computation ...\n",
      "{'dtini_g': 300.0, 't0_g': 0.0, 'tfin_g': 2.0, 'saveinterval_g': 300.0, 'saveinterval_ev_g': 300.0, 'dt_ql_g': 3600.0, 'dt_ub_g': 3600.0, 'dt_db_g': 900.0, 'nts_ql_g': 3, 'nts_ub_g': 3, 'nts_db_g': 93, 'mxncomp_g': 7, 'nrch_g': 445, 'z_ar_g': array([[192.22999573, 210.22999573, 181.94999695, ...,  97.52999878,\n",
      "         74.69000244,  74.69000244],\n",
      "       [192.17999268, 210.22999573, 180.78999329, ...,  77.30999756,\n",
      "         74.69000244,  74.66497244],\n",
      "       [186.16000366, 181.94999695,   0.        , ...,  74.69000244,\n",
      "          0.        ,   0.        ],\n",
      "       ...,\n",
      "       [181.94999695,   0.        ,   0.        , ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
      "          0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
      "          0.        ,   0.        ]]), 'bo_ar_g': array([[ 1.14838398,  0.52687401,  3.27630115, ...,  1.47550988,\n",
      "        17.08355331, 17.14519501],\n",
      "       [ 1.3770504 ,  3.14552617,  3.27630115, ...,  1.96888828,\n",
      "        17.08355331, 17.14519501],\n",
      "       [ 1.41200352,  3.14552617,  0.        , ...,  2.3926177 ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 1.45448256,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'traps_ar_g': array([[1.14107597, 0.80915016, 1.81209421, ..., 1.27449703, 3.75482821,\n",
      "        3.76079893],\n",
      "       [1.23625183, 1.77982008, 1.81209421, ..., 1.44746792, 3.75482821,\n",
      "        3.76079893],\n",
      "       [1.24999869, 1.77982008, 0.        , ..., 1.5774498 , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [1.26645195, 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ]]), 'tw_ar_g': array([[ 1.91397333,  0.87812334,  5.46050215, ...,  2.45918322,\n",
      "        28.47258949, 28.57532692],\n",
      "       [ 2.295084  ,  5.24254322,  5.46050215, ...,  3.28148055,\n",
      "        28.47258949, 28.57532692],\n",
      "       [ 2.3533392 ,  5.24254322,  0.        , ...,  3.98769617,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 2.42413759,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'twcc_ar_g': array([[ 5.74191999,  2.63437009, 16.38150597, ...,  7.37754965,\n",
      "        85.41777039, 85.72598267],\n",
      "       [ 6.885252  , 15.72763062, 16.38150597, ...,  9.84444141,\n",
      "        85.41777039, 85.72598267],\n",
      "       [ 7.06001806, 15.72763062,  0.        , ..., 11.96308899,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 7.27241325,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'mann_ar_g': array([[0.06, 0.06, 0.06, ..., 0.06, 0.05, 0.05],\n",
      "       [0.06, 0.06, 0.06, ..., 0.06, 0.05, 0.05],\n",
      "       [0.06, 0.06, 0.  , ..., 0.06, 0.  , 0.  ],\n",
      "       ...,\n",
      "       [0.06, 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
      "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
      "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]]), 'manncc_ar_g': array([[0.12, 0.12, 0.12, ..., 0.12, 0.1 , 0.1 ],\n",
      "       [0.12, 0.12, 0.12, ..., 0.12, 0.1 , 0.1 ],\n",
      "       [0.12, 0.12, 0.  , ..., 0.12, 0.  , 0.  ],\n",
      "       ...,\n",
      "       [0.12, 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
      "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
      "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]]), 'so_ar_g': array([[2.00000009e-03, 9.99999975e-06, 4.00000019e-03, ...,\n",
      "        1.60000008e-02, 9.99999975e-06, 9.99999975e-06],\n",
      "       [1.89999994e-02, 4.99999989e-03, 4.00000019e-03, ...,\n",
      "        3.00000003e-03, 9.99999975e-06, 9.99999975e-06],\n",
      "       [3.00000003e-03, 4.99999989e-03, 0.00000000e+00, ...,\n",
      "        9.99999975e-06, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [1.30000003e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]), 'dx_ar_g': array([[ 138.,  149.,  329., ..., 1393., 1701., 2503.],\n",
      "       [ 321., 5935.,  329., ...,  809., 1701., 2503.],\n",
      "       [ 131., 5935.,    0., ...,  950.,    0.,    0.],\n",
      "       ...,\n",
      "       [ 293.,    0.,    0., ...,    0.,    0.,    0.],\n",
      "       [   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
      "       [   0.,    0.,    0., ...,    0.,    0.,    0.]]), 'nhincr_m_g': 20, 'nhincr_f_g': 20, 'ufhlt_m_g': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]]), 'ufqlt_m_g': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]]), 'ufhlt_f_g': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]]), 'ufqlt_f_g': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]]), 'frnw_col': 8, 'frnw_g': array([[  5,   3,   0, ...,   0,   0,   0],\n",
      "       [  3,   3,   0, ...,   0,   0,   0],\n",
      "       [  2,   8,   2, ...,   0,   0,   0],\n",
      "       ...,\n",
      "       [  4, 445,   0, ...,   0,   0,   0],\n",
      "       [  2, 445,   3, ..., 441,   0,   0],\n",
      "       [  2, -99,   3, ..., 444,   0,   0]]), 'qlat_g': array([[[0.00000000e+00, 0.00000000e+00, 1.80350826e-03, ...,\n",
      "         0.00000000e+00, 1.45750482e-05, 5.14579378e-03],\n",
      "        [3.12726782e-03, 2.98099238e-02, 0.00000000e+00, ...,\n",
      "         9.80617385e-03, 0.00000000e+00, 0.00000000e+00],\n",
      "        [5.83831803e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         6.96983945e-04, 0.00000000e+00, 0.00000000e+00],\n",
      "        ...,\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
      "\n",
      "       [[0.00000000e+00, 0.00000000e+00, 1.80281326e-03, ...,\n",
      "         0.00000000e+00, 1.45195136e-05, 5.14071202e-03],\n",
      "        [3.12633882e-03, 2.97530219e-02, 0.00000000e+00, ...,\n",
      "         9.75619815e-03, 0.00000000e+00, 0.00000000e+00],\n",
      "        [5.83638262e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         6.95796858e-04, 0.00000000e+00, 0.00000000e+00],\n",
      "        ...,\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
      "\n",
      "       [[0.00000000e+00, 0.00000000e+00, 1.80220755e-03, ...,\n",
      "         0.00000000e+00, 1.44653022e-05, 5.13567869e-03],\n",
      "        [3.12557118e-03, 2.97068972e-02, 0.00000000e+00, ...,\n",
      "         9.70726553e-03, 0.00000000e+00, 0.00000000e+00],\n",
      "        [5.83475106e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         6.94644987e-04, 0.00000000e+00, 0.00000000e+00],\n",
      "        ...,\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]]), 'ubcd_g': array([[3.72515708e-01, 4.45316127e-03, 0.00000000e+00, ...,\n",
      "        5.87621260e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [3.72399926e-01, 4.44665086e-03, 0.00000000e+00, ...,\n",
      "        5.85336399e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [3.72301936e-01, 4.44016652e-03, 0.00000000e+00, ...,\n",
      "        5.83107996e+00, 0.00000000e+00, 0.00000000e+00]]), 'dbcd_g': array([77.8367773 , 77.8367773 , 77.83982363, 77.83982363, 77.84286995,\n",
      "       77.83982363, 77.83982363, 77.84286995, 77.83982363, 77.84286995,\n",
      "       77.83982363, 77.83982363, 77.83982363, 77.83982363, 77.83982363,\n",
      "       77.83982363, 77.83982363, 77.8367773 , 77.8367773 , 77.8367773 ,\n",
      "       77.8367773 , 77.8367773 , 77.8367773 , 77.8367773 , 77.83372633,\n",
      "       77.8367773 , 77.83982363, 77.8367773 , 77.8367773 , 77.8367773 ,\n",
      "       77.83982363, 77.83982363, 77.8367773 , 77.8367773 , 77.83982363,\n",
      "       77.8367773 , 77.83372633, 77.83372633, 77.8367773 , 77.8367773 ,\n",
      "       77.83372633, 77.83372633, 77.8367773 , 77.8367773 , 77.8367773 ,\n",
      "       77.8367773 , 77.8367773 , 77.8367773 , 77.83372633, 77.83372633,\n",
      "       77.83372633, 77.8367773 , 77.83372633, 77.83372633, 77.8367773 ,\n",
      "       77.83372633, 77.8367773 , 77.83372633, 77.8367773 , 77.83982363,\n",
      "       77.83372633, 77.8367773 , 77.83372633, 77.8367773 , 77.83372633,\n",
      "       77.83372633, 77.83372633, 77.83068   , 77.82763367, 77.83068   ,\n",
      "       77.83068   , 77.83372633, 77.83372633, 77.83372633, 77.84286995,\n",
      "       77.83982363, 77.83982363, 77.84896726, 77.84896726, 77.86420819,\n",
      "       77.86420819, 77.86116186, 77.85811088, 77.86420819, 77.86420819,\n",
      "       77.85811088, 77.85506456, 77.85811088, 77.85811088, 77.85506456,\n",
      "       77.85506456, 77.85811088, 77.86420819]), 'cfl_g': 0.9, 'theta_g': 1.0, 'tzeq_flag_g': 1, 'y_opt_g': 1, 'so_llm_g': 0.0001, 'ntss_ev_g': 25}\n",
      "input data preparation for diffusive routing complete\n",
      "... in 3.7659544944763184 seconds.\n",
      "ordered reach computation complete\n",
      "... in 4.0433127880096436 seconds.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# example usage: python compute_nhd_routing_SingleSeg.py -v -t -w -n Mainstems_CONUS\n",
    "# python compute_nhd_routing_SingleSeg_v02.py --test -t -v --debuglevel 1\n",
    "# python compute_nhd_routing_SingleSeg_v02.py --test-full-pocono -t -v --debuglevel 1\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"NHD Network traversal\n",
    "\n",
    "A demonstration version of this code is stored in this Colaboratory notebook:\n",
    "    https://colab.research.google.com/drive/1ocgg1JiOGBUl3jfSUPCEVnW5WNaqLKCD\n",
    "\n",
    "\"\"\"\n",
    "## Parallel execution\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pathlib\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from joblib import delayed, Parallel\n",
    "from itertools import chain, islice\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "\n",
    "ENV_IS_CL = False\n",
    "if ENV_IS_CL:\n",
    "    root = pathlib.Path(\"/\", \"content\", \"t-route\")\n",
    "elif not ENV_IS_CL:\n",
    "    #root = pathlib.Path(\"../..\").resolve()\n",
    "    # sys.path.append(r\"../python_framework_v02\")\n",
    "    # TODO: automate compile for the package scripts\n",
    "    #sys.path.append(\"fast_reach\")\n",
    "    root = os.path.dirname(os.path.dirname(os.path.abspath('')))\n",
    "    sys.path.append(os.path.join(root, r'src', r'python_framework_v02','troute'))\n",
    "    sys.path.append(os.path.join(root, r'src', r'python_routing_v02','fast_reach'))\n",
    "\n",
    "\n",
    "import troute.nhd_network_utilities_v02 as nnu\n",
    "import mc_reach\n",
    "import troute.nhd_network as nhd_network\n",
    "import troute.nhd_io as nhd_io\n",
    "import build_tests  # TODO: Determine whether and how to incorporate this into setup.py\n",
    "# import troute.nhd_network_augment as nna\n",
    "\n",
    "\"\"\"\n",
    "def writetoFile(file, writeString):\n",
    "    file.write(writeString)\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "\n",
    "def constant_qlats(index_dataset, nsteps, qlat):\n",
    "    q = np.full((len(index_dataset.index), nsteps), qlat, dtype=\"float32\")\n",
    "    ql = pd.DataFrame(q, index=index_dataset.index, columns=range(nsteps))\n",
    "    return ql\n",
    "\n",
    "def diffusive_routing_v02(\n",
    "    connections,\n",
    "    rconn,\n",
    "    reaches_bytw,\n",
    "    compute_func,\n",
    "    parallel_compute_method,\n",
    "    subnetwork_target_size,\n",
    "    cpu_pool,\n",
    "    nts,\n",
    "    qts_subdivisions,\n",
    "    independent_networks,\n",
    "    param_df,\n",
    "    qlats,\n",
    "    q0,\n",
    "    assume_short_ts,\n",
    "):\n",
    "    start_time = time.time()\n",
    "\n",
    "    if parallel_compute_method == \"by-network\":\n",
    "        with Parallel(n_jobs=cpu_pool, backend=\"threading\") as parallel:\n",
    "            jobs = []\n",
    "            for twi, (tw, reach_list) in enumerate(reaches_bytw.items(), 1):\n",
    "                segs = list(chain.from_iterable(reach_list))\n",
    "                param_df_sub = param_df.loc[\n",
    "                    segs, [\"dt\", \"bw\", \"tw\", \"twcc\", \"dx\", \"n\", \"ncc\", \"cs\", \"s0\"]\n",
    "                ].sort_index()\n",
    "                qlat_sub = qlats.loc[segs].sort_index()\n",
    "                q0_sub = q0.loc[segs].sort_index()\n",
    "                jobs.append(\n",
    "                    delayed(compute_func)(\n",
    "                        nts,\n",
    "                        qts_subdivisions,\n",
    "                        reach_list,\n",
    "                        independent_networks[tw],\n",
    "                        param_df_sub.index.values,\n",
    "                        param_df_sub.columns.values,\n",
    "                        param_df_sub.values,\n",
    "                        qlat_sub.values,\n",
    "                        q0_sub.values,\n",
    "                        {},\n",
    "                        assume_short_ts,\n",
    "                    )\n",
    "                )\n",
    "            results = parallel(jobs)\n",
    "\n",
    "    else:  # Execute in serial\n",
    "        results = []\n",
    "        for twi, (tw, reach_list) in enumerate(reaches_bytw.items(), 1):\n",
    "            segs = list(chain.from_iterable(reach_list))\n",
    "            param_df_sub = param_df.loc[\n",
    "                segs, [\"dt\", \"bw\", \"tw\", \"twcc\", \"dx\", \"n\", \"ncc\", \"cs\", \"s0\"]\n",
    "            ].sort_index()\n",
    "            qlat_sub = qlats.loc[segs].sort_index()\n",
    "            q0_sub = q0.loc[segs].sort_index()\n",
    "            \n",
    "            if tw==8777215:\n",
    "                print(f\"tw:{tw} reach_list{reach_list}\")\n",
    "                results.append(\n",
    "                    compute_func(\n",
    "                        nts,\n",
    "                        qts_subdivisions,\n",
    "                        reach_list,\n",
    "                        independent_networks[tw],\n",
    "                        param_df_sub.index.values,\n",
    "                        param_df_sub.columns.values,\n",
    "                        param_df_sub.values,\n",
    "                        qlat_sub.values,\n",
    "                        q0_sub.values,\n",
    "                        {},\n",
    "                        assume_short_ts,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return results\n",
    "\"\"\"\n",
    "def diffusive_input_data_v02(connections\n",
    "                            , rconn\n",
    "                            , reaches_bytw\n",
    "                            , diffusive_parameters\n",
    "                            , param_df\n",
    "                            , qlats\n",
    "                            ):\n",
    "\n",
    "    start_time= time.time()\n",
    "    \n",
    "    import itertools\n",
    "    import RouteLink_adjustment_v02 as rladj\n",
    "    import fortran_python_map_v02 as fpm\n",
    "    #from pyuniflowtzlt import uniflow_lookuptable\n",
    "\n",
    "    usgs_retrievaltool_path= diffusive_parameters.get(\"usgs_retrievaltool_path\",None)\n",
    "    sys.path.append(usgs_retrievaltool_path)\n",
    "    #results = []\n",
    "    # diffusive time steps info.\n",
    "    dt_ql_g=diffusive_parameters.get(\"dt_qlat\",None) # time step of lateral flow\n",
    "    dt_ub_g=diffusive_parameters.get(\"dt_upstream_boundary\",None) # time step of us.boundary data\n",
    "    dt_db_g=diffusive_parameters.get(\"dt_downstream_boundary\",None) # time step of ds.boundary data\n",
    "    saveinterval_g=diffusive_parameters.get(\"dt_output\",None) # time step for outputting routed results\n",
    "    saveinterval_ev_g=diffusive_parameters.get(\"dt_output\",None) # time step for evaluating routed results\n",
    "    dtini_g=diffusive_parameters.get(\"dt_diffusive\",None) # initial simulation time step\n",
    "    t0_g=0.0 #simulation start hr **set to zero for Fortran computation \n",
    "    tfin_g=diffusive_parameters.get(\"simulation_end_hr\",None) # simulation end time\n",
    "\n",
    "    # USGS data related info.\n",
    "    usgsID= diffusive_parameters.get(\"usgsID\",None)\n",
    "    seg2usgsID= diffusive_parameters.get(\"link2usgsID\",None)\n",
    "    usgssDT= diffusive_parameters.get(\"usgs_start_date\",None)\n",
    "    usgseDT= diffusive_parameters.get(\"usgs_end_date\",None)\n",
    "    usgspCd= diffusive_parameters.get(\"usgs_parameterCd\",None)\n",
    "\n",
    "    # diffusive parameters\n",
    "    cfl_g= diffusive_parameters.get(\"courant_number_upper_limit\",None)\n",
    "    theta_g= diffusive_parameters.get(\"theta_parameter\",None)\n",
    "    tzeq_flag_g= diffusive_parameters.get(\"chgeo_computation_flag\",None)\n",
    "    y_opt_g= diffusive_parameters.get(\"water_elevation_computation_flag\",None)\n",
    "    so_llm_g= diffusive_parameters.get(\"bed_slope_lower_limit\",None)\n",
    "\n",
    "    for twi, (tw, reach_list) in enumerate(reaches_bytw.items(), 1):\n",
    "    \n",
    "        if tw==933020089:  #if tw==8777215 or tw==166737669:\n",
    "            # downstream boundary (tw) segment ID -> make an additional fake tw segment\n",
    "            dbfksegID= str(tw)+ str(2)\n",
    "            dbfksegID= int(dbfksegID) \n",
    "            ordered_reaches={}\n",
    "            rchhead_reaches={}\n",
    "            rchbottom_reaches={}\n",
    "            z_all={}\n",
    "    \n",
    "            flat_list=list(itertools.chain(*reaches_bytw[tw])) # a list of all segments of reaches_bytw for a given tw.\n",
    "            rconn_tw={key:value for key, value in rconn.items() if key in flat_list} # subset rconn by flat_list\n",
    "            connections_tw= {key:value for key, value in connections.items() if key in flat_list} # subset connections by flat_list\n",
    "\n",
    "            path_func = partial(nhd_network.split_at_junction, rconn_tw)\n",
    "            tr = nhd_network.dfs_decomposition_depth_tuple(rconn_tw, path_func)\n",
    "            jorder_reaches_tw=sorted(tr, key=lambda x: x[0]) # [ (jorder:[segments]), ... , (jorder:[segments]) ] \n",
    "\n",
    "            mx_jorder_tw=max(jorder_reaches_tw)[0] # maximum junction order of subnetwork of TW\n",
    "            nrch_g=len(jorder_reaches_tw) # the number of reaches        \n",
    "            maxlist=max(jorder_reaches_tw, key=lambda i:len(i[1]))\n",
    "            mxncomp_g= len(maxlist[1])+1 # max. number of nodes (segments+one additional segment) within a reach\n",
    "\n",
    "            for i in jorder_reaches_tw:\n",
    "                # add one more segment(fake) to the end of a list of segments to account for node configuration.\n",
    "                fksegID= i[1][len(i[1])-1]\n",
    "                fksegID= int(str(fksegID) + str(2))\n",
    "                i[1].append(fksegID)\n",
    "                # additional segment(fake) to upstream bottom segments\n",
    "                fk_usbseg=[int(str(x)+str(2)) for x in rconn_tw[i[1][0]]]            \n",
    "\n",
    "                if i[0] not in ordered_reaches:\n",
    "                    ordered_reaches.update({i[0]:[]})\n",
    "                ordered_reaches[i[0]].append([i[1][0],{'number_segments':len(i[1]),\\\n",
    "                                            'segments_list':i[1],\\\n",
    "                                            'upstream_bottom_segments':fk_usbseg,\\\n",
    "                                            'downstream_head_segment':connections_tw[i[1][len(i[1])-2]]}]) \n",
    "\n",
    "                if i[1][0] not in rchhead_reaches:    \n",
    "                    # a list of segments for a given head segment\n",
    "                    rchhead_reaches.update({i[1][0]:{\"number_segments\":len(i[1]),\\\n",
    "                                                \"segments_list\":i[1]}})\n",
    "                    # a list of segments for a given bottom segment\n",
    "                    rchbottom_reaches.update({i[1][len(i[1])-1]:{\"number_segments\":len(i[1]),\\\n",
    "                                                         \"segments_list\":i[1]}})\n",
    "                # for channel altitude adjustment\n",
    "                z_all.update({seg:{'adj.alt':np.zeros(1)}\n",
    "                                            for seg in i[1]})\n",
    "            # cahnnel geometry data\n",
    "            ch_geo_data_tw = param_df.loc[\n",
    "            flat_list, [\"bw\", \"tw\", \"twcc\", \"dx\", \"n\", \"ncc\", \"cs\", \"s0\", \"alt\"]]\n",
    "            ch_geo_data_tw[:][\"cs\"]= 1.0/ch_geo_data_tw[:][\"cs\"]\n",
    "        #--------------------------------------------------------------------------------------\n",
    "        #                                 Step 0-3           \n",
    "\n",
    "        #    Adjust altitude so that altitude of the last sement of a reach is equal to that \n",
    "        #    of the first segment of its downstream reach right after their common junction.\n",
    "        #--------------------------------------------------------------------------------------\n",
    "            rladj.adj_alt1(mx_jorder_tw\n",
    "                        , ordered_reaches\n",
    "                        , ch_geo_data_tw\n",
    "                        , dbfksegID\n",
    "                        , z_all\n",
    "                        ) \n",
    "        #--------------------------------------------------------------------------------------\n",
    "        #                                 Step 0-4           \n",
    "\n",
    "        #     Make Fortran-Python channel network mapping variables.\n",
    "        #--------------------------------------------------------------------------------------   \n",
    "            pynw={}\n",
    "            frj=-1\n",
    "            for x in range(mx_jorder_tw,-1,-1): \n",
    "                for head_segment, reach in ordered_reaches[x]:\n",
    "                    frj= frj+1\n",
    "                    pynw[frj]=head_segment\n",
    "\n",
    "            #frnw_col=8\n",
    "            frnw_col= diffusive_parameters.get(\"fortran_nework_map_col_number\",None)\n",
    "            frnw_g=fpm.fp_network_map(mx_jorder_tw\n",
    "                    , ordered_reaches\n",
    "                    , rchbottom_reaches\n",
    "                    , nrch_g\n",
    "                    , frnw_col\n",
    "                    , dbfksegID\n",
    "                    , pynw\n",
    "                    )  \n",
    "            #covert data type from integer to float for frnw\n",
    "            dfrnw_g=np.zeros((nrch_g,frnw_col), dtype=float)\n",
    "            for j in range(0,nrch_g):\n",
    "                for col in range(0,frnw_col):\n",
    "                    dfrnw_g[j,col]=float(frnw_g[j,col])\n",
    "        #---------------------------------------------------------------------------------\n",
    "        #                              Step 0-5\n",
    "\n",
    "        #                  Prepare channel geometry data           \n",
    "        #---------------------------------------------------------------------------------    \n",
    "            z_ar_g, bo_ar_g, traps_ar_g, tw_ar_g, twcc_ar_g, mann_ar_g, manncc_ar_g, so_ar_g, dx_ar_g= fpm.fp_chgeo_map(mx_jorder_tw\n",
    "                        , ordered_reaches\n",
    "                        , ch_geo_data_tw\n",
    "                        , z_all\n",
    "                        , mxncomp_g\n",
    "                        , nrch_g                    \n",
    "                        )   \n",
    "        #---------------------------------------------------------------------------------\n",
    "        #                              Step 0-6\n",
    "\n",
    "        #                  Prepare lateral inflow data           \n",
    "        #---------------------------------------------------------------------------------\n",
    "            segs = list(chain.from_iterable(reach_list))\n",
    "            qlat_tw = qlats.loc[segs]    \n",
    "            #tfin_g=len(qlat_tw.columns)-1 #entire simulation period in hrs\n",
    "            nts_ql_g= int((tfin_g-t0_g)*3600.0/dt_ql_g)+1 # the number of the entire time steps of lateral flow data \n",
    "\n",
    "            qlat_g=np.zeros((nts_ql_g, mxncomp_g, nrch_g)) \n",
    "\n",
    "            fpm.fp_qlat_map(mx_jorder_tw\n",
    "                , ordered_reaches\n",
    "                , nts_ql_g\n",
    "                , qlat_tw            \n",
    "                , qlat_g\n",
    "                ) \n",
    "        #---------------------------------------------------------------------------------\n",
    "        #                              Step 0-7\n",
    "\n",
    "        #       Prepare upstream boundary (top segments of head basin reaches) data            \n",
    "        #---------------------------------------------------------------------------------\n",
    "            nts_ub_g= nts_ql_g \n",
    "            ubcd_g = fpm.fp_ubcd_map(frnw_g\n",
    "                                    , pynw\n",
    "                                    , nts_ub_g\n",
    "                                    , nrch_g\n",
    "                                    , ch_geo_data_tw\n",
    "                                    , qlat_tw\n",
    "                                    , qlat_g\n",
    "                                    )\n",
    "        #---------------------------------------------------------------------------------\n",
    "        #                              Step 0-8\n",
    "\n",
    "        #       Prepare downstrea boundary (bottom segments of TW reaches) data            \n",
    "        #---------------------------------------------------------------------------------        \n",
    "            #import pdb; pdb.set_trace()\n",
    "            if tw in seg2usgsID:\n",
    "                ipos= seg2usgsID.index(tw)\n",
    "                usgsID2tw= usgsID[ipos]         \n",
    "                nts_db_g, dbcd_g=fpm.fp_dbcd_map(usgsID2tw\n",
    "                            , usgssDT\n",
    "                            , usgseDT\n",
    "                            , usgspCd\n",
    "                            )\n",
    "            else:\n",
    "                # no usgs data available at this TW.\n",
    "                nts_db_g=-1.0\n",
    "                \n",
    "        #---------------------------------------------------------------------------------\n",
    "        #                              Step 0-8\n",
    "\n",
    "        #                 Prepare uniform flow lookup tables            \n",
    "        #---------------------------------------------------------------------------------          \n",
    "            #nhincr_m_g=20\n",
    "            #nhincr_f_g=20               \n",
    "            #timesdepth_g=10\n",
    "            nhincr_m_g= diffusive_parameters.get(\"normaldepth_lookuptable_main_increment_number\",None) \n",
    "            nhincr_f_g= diffusive_parameters.get(\"normaldepth_lookuptable_floodplain_increment_number\",None) \n",
    "            timesdepth_g= diffusive_parameters.get(\"normaldepth_lookuptable_depth_multiplier\",None)\n",
    "            ufqlt_m_g= np.zeros((mxncomp_g,nrch_g,nhincr_m_g))                        \n",
    "            ufhlt_m_g= np.zeros((mxncomp_g,nrch_g,nhincr_m_g))\n",
    "            ufqlt_f_g= np.zeros((mxncomp_g,nrch_g,nhincr_f_g))\n",
    "            ufhlt_f_g= np.zeros((mxncomp_g,nrch_g,nhincr_f_g))\n",
    "            #ufhlt_m_g, ufqlt_m_g, ufhlt_f_g, ufqlt_f_g= uniflow_lookuptable(mxncomp_g \n",
    "            #                                                            , nrch_g \n",
    "            #                                                            , bo_ar_g \n",
    "            #                                                            , traps_ar_g \n",
    "            #                                                            , tw_ar_g \n",
    "            #                                                            , twcc_ar_g \n",
    "            #                                                            , mann_ar_g \n",
    "            #                                                            , manncc_ar_g \n",
    "            #                                                            , so_ar_g \n",
    "            #                                                            , nhincr_m_g \n",
    "            #                                                            , nhincr_f_g               \n",
    "            #                                                            , frnw_col \n",
    "            #                                                            , dfrnw_g \n",
    "            #                                                            , timesdepth_g)\n",
    "\n",
    "        #---------------------------------------------------------------------------------\n",
    "        #                              Step 0-9\n",
    "\n",
    "        #                       Run diffusive model            \n",
    "        #---------------------------------------------------------------------------------  \n",
    "            ntss_ev_g= int((tfin_g - t0_g)*3600.0/saveinterval_ev_g)+1 \n",
    "            q_ev_g=np.zeros((ntss_ev_g, mxncomp_g, nrch_g))\n",
    "            elv_ev_g=np.zeros((ntss_ev_g, mxncomp_g, nrch_g))\n",
    "            \n",
    "            # build a dictionary of diffusive model inputs\n",
    "            diff_ins = {}\n",
    "            diff_ins[\"dtini_g\"] = dtini_g\n",
    "            diff_ins[\"t0_g\"] = t0_g\n",
    "            diff_ins[\"tfin_g\"] = tfin_g\n",
    "            diff_ins[\"saveinterval_g\"] = saveinterval_g\n",
    "            diff_ins[\"saveinterval_ev_g\"] = saveinterval_ev_g\n",
    "            diff_ins[\"dt_ql_g\"] = dt_ql_g\n",
    "            diff_ins[\"dt_ub_g\"] = dt_ub_g\n",
    "            diff_ins[\"dt_db_g\"] = dt_db_g\n",
    "            diff_ins[\"nts_ql_g\"] = nts_ql_g\n",
    "            diff_ins[\"nts_ub_g\"] = nts_ub_g\n",
    "            diff_ins[\"nts_db_g\"] = nts_db_g\n",
    "            diff_ins[\"mxncomp_g\"] = mxncomp_g\n",
    "            diff_ins[\"nrch_g\"] = nrch_g\n",
    "            diff_ins[\"z_ar_g\"] = z_ar_g\n",
    "            diff_ins[\"bo_ar_g\"] = bo_ar_g\n",
    "            diff_ins[\"traps_ar_g\"] = traps_ar_g\n",
    "            diff_ins[\"tw_ar_g\"] = tw_ar_g\n",
    "            diff_ins[\"twcc_ar_g\"] = twcc_ar_g\n",
    "            diff_ins[\"mann_ar_g\"] = mann_ar_g\n",
    "            diff_ins[\"manncc_ar_g\"] = manncc_ar_g\n",
    "            diff_ins[\"so_ar_g\"] = so_ar_g\n",
    "            diff_ins[\"dx_ar_g\"] = dx_ar_g\n",
    "            diff_ins[\"nhincr_m_g\"] = nhincr_m_g\n",
    "            diff_ins[\"nhincr_f_g\"] = nhincr_f_g\n",
    "            diff_ins[\"ufhlt_m_g\"] = ufhlt_m_g\n",
    "            diff_ins[\"ufqlt_m_g\"] = ufqlt_m_g\n",
    "            diff_ins[\"ufhlt_f_g\"] = ufhlt_f_g\n",
    "            diff_ins[\"ufqlt_f_g\"] = ufqlt_f_g\n",
    "            diff_ins[\"frnw_col\"] = frnw_col\n",
    "            diff_ins[\"frnw_g\"] = frnw_g\n",
    "            diff_ins[\"qlat_g\"] = qlat_g\n",
    "            diff_ins[\"ubcd_g\"] = ubcd_g\n",
    "            diff_ins[\"dbcd_g\"] = dbcd_g\n",
    "            diff_ins[\"cfl_g\"] = cfl_g\n",
    "            diff_ins[\"theta_g\"] = theta_g\n",
    "            diff_ins[\"tzeq_flag_g\"] = tzeq_flag_g\n",
    "            diff_ins[\"y_opt_g\"] = y_opt_g\n",
    "            diff_ins[\"so_llm_g\"] = so_llm_g\n",
    "            diff_ins[\"ntss_ev_g\"] = ntss_ev_g\n",
    "            \n",
    "            # save input data as yaml\n",
    "            import yaml\n",
    "            with open('diff_inputs.yml', 'w') as outfile:\n",
    "                yaml.dump(diff_ins, outfile, default_flow_style=False)\n",
    "            \n",
    "    print(\"input data preparation for diffusive routing complete\")\n",
    "    print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "def _input_handler():\n",
    "\n",
    "    #args = _handle_args()\n",
    "\n",
    "    #custom_input_file = args.custom_input_file\n",
    "    custom_input_file=\"../../test/input/yaml/CustomInput_florence_933020089_dt300.yaml\"\n",
    "    \n",
    "    supernetwork_parameters = {}\n",
    "    waterbody_parameters = {}\n",
    "    forcing_parameters = {}\n",
    "    restart_parameters = {}\n",
    "    output_parameters = {}\n",
    "    run_parameters = {}\n",
    "    parity_parameters = {}\n",
    "    diffusive_parameters={}\n",
    "\n",
    "    if custom_input_file:\n",
    "        (\n",
    "            supernetwork_parameters,\n",
    "            waterbody_parameters,\n",
    "            forcing_parameters,\n",
    "            restart_parameters,\n",
    "            output_parameters,\n",
    "            run_parameters,\n",
    "            parity_parameters,\n",
    "            diffusive_parameters,\n",
    "        ) = nhd_io.read_custom_input(custom_input_file)\n",
    "        run_parameters[\"debuglevel\"] *= -1\n",
    "        print(f\"in here: custom_input_file\")\n",
    "\n",
    "    else:\n",
    "        print(f\"deleted here\")\n",
    "    \n",
    "    return (\n",
    "        supernetwork_parameters,\n",
    "        waterbody_parameters,\n",
    "        forcing_parameters,\n",
    "        restart_parameters,\n",
    "        output_parameters,\n",
    "        run_parameters,\n",
    "        parity_parameters,\n",
    "        diffusive_parameters,\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "     \n",
    "    (\n",
    "        supernetwork_parameters,\n",
    "        waterbody_parameters,\n",
    "        forcing_parameters,\n",
    "        restart_parameters,         \n",
    "        output_parameters,\n",
    "        run_parameters,\n",
    "        parity_parameters,\n",
    "        diffusive_parameters,\n",
    "    ) = _input_handler()\n",
    "   \n",
    "    dt = run_parameters.get(\"dt\", None)\n",
    "    nts = run_parameters.get(\"nts\", None)\n",
    "    verbose = run_parameters.get(\"verbose\", None)\n",
    "    showtiming = run_parameters.get(\"showtiming\", None)\n",
    "    debuglevel = run_parameters.get(\"debuglevel\", 0)\n",
    "    \n",
    "\n",
    "    geo_file_path = supernetwork_parameters.get(\"geo_file_path\", None)\n",
    "    print(f\"geo_file_path:{geo_file_path}\")    \n",
    "\n",
    "    if verbose:\n",
    "        print(\"creating supernetwork connections set\")\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "\n",
    "    # STEP 1: Build basic network connections graph\n",
    "    print(supernetwork_parameters)\n",
    "    connections, param_df = nnu.build_connections(supernetwork_parameters, dt)\n",
    "    #print(connections)\n",
    "     \n",
    "    if verbose:\n",
    "        print(\"supernetwork connections set complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "    # STEP 2: Identify Independent Networks and Reaches by Network\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"organizing connections into reaches ...\")\n",
    "\n",
    "    independent_networks, reaches_bytw, rconn = nnu.organize_independent_networks(\n",
    "        connections\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"reach organization complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "    # STEP 4: Handle Channel Initial States\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"setting channel initial states ...\")\n",
    "\n",
    "    q0 = nnu.build_channel_initial_state(restart_parameters, param_df.index)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"channel initial states complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "    # STEP 5: Read (or set) QLateral Inputs\n",
    "    if showtiming:\n",
    "        start_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"creating qlateral array ...\")\n",
    "\n",
    "    qlats = nnu.build_qlateral_array(forcing_parameters, connections.keys(), nts)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"qlateral array complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "    ################### Main Execution Loop across ordered networks\n",
    "    if showtiming:\n",
    "        main_start_time = time.time()\n",
    "    if verbose:\n",
    "        print(f\"executing routing computation ...\")\n",
    "        \n",
    "    \n",
    "    # Prepare input datasets for diffusive routing\n",
    "    diffusive_input_data_v02(connections\n",
    "                            , rconn\n",
    "                            , reaches_bytw\n",
    "                            , diffusive_parameters\n",
    "                            , param_df \n",
    "                            , qlats\n",
    "                            )\n",
    "\n",
    "    #if run_parameters.get(\"compute_method\", None) == \"standard cython compute network\":\n",
    "    #    compute_func = mc_reach.compute_network\n",
    "    #else:\n",
    "    #    compute_func = mc_reach.compute_network\n",
    "\n",
    "    #results = diffusive_routing_v02(\n",
    "    #    connections,\n",
    "    #    rconn,\n",
    "    #    reaches_bytw,\n",
    "    #    compute_func,\n",
    "    #    run_parameters.get(\"parallel_compute_method\", None),\n",
    "    #    run_parameters.get(\"subnetwork_target_size\", 1),\n",
    "        # The default here might be the whole network or some percentage...\n",
    "    #    run_parameters.get(\"cpu_pool\", None),\n",
    "    #    run_parameters.get(\"nts\", 1),\n",
    "    #    run_parameters.get(\"qts_subdivisions\", 1),\n",
    "    #    independent_networks,\n",
    "    #    param_df,\n",
    "    #    qlats,\n",
    "    #    q0,\n",
    "    #    run_parameters.get(\"assume_short_ts\", False),\n",
    "    #)\n",
    "\n",
    "    #csv_output_folder = output_parameters.get(\"csv_output_folder\", None)\n",
    "    #if (debuglevel <= -1) or csv_output_folder:\n",
    "    #    qvd_columns = pd.MultiIndex.from_product(\n",
    "    #        [range(nts), [\"q\", \"v\", \"d\"]]\n",
    "    #    ).to_flat_index()\n",
    "    #    flowveldepth = pd.concat(\n",
    "    #        [pd.DataFrame(d, index=i, columns=qvd_columns) for i, d in results],\n",
    "    #        copy=False,\n",
    "    #    )\n",
    "\n",
    "    #    if csv_output_folder:\n",
    "    #        flowveldepth = flowveldepth.sort_index()\n",
    "    #        output_path = pathlib.Path(csv_output_folder).resolve()\n",
    "    #        flowveldepth.to_csv(output_path.joinpath(f\"{args.supernetwork}.csv\"))\n",
    "\n",
    "    #    if debuglevel <= -1:\n",
    "    #        print(flowveldepth)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ordered reach computation complete\")\n",
    "    if showtiming:\n",
    "        print(\"... in %s seconds.\" % (time.time() - start_time))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qlats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4fd920a758f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqlats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'qlats' is not defined"
     ]
    }
   ],
   "source": [
    "qlats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
