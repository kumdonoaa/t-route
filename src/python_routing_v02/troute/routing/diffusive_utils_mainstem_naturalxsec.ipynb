{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial, reduce\n",
    "import troute.nhd_network as nhd_network\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "\n",
    "def adj_alt1(\n",
    "    mx_jorder, ordered_reaches, geo_cols, geo_index, geo_data, dbfksegID, z_all\n",
    "):\n",
    "    \"\"\"\n",
    "    Adjust reach altitude data so that altitude of last node in reach is equal to that of the head segment of\n",
    "    the neighboring downstream reach. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mx_jorder -- (int) maximum network reach order\n",
    "    geo_cols -- (ndarray of strs) column headers for geomorphic parameters data array (geo_data)\n",
    "    geo_index -- (ndarray of int64s) row indices for geomorphic parameters data array (geo_data)\n",
    "    geo_data --(ndarray of float32s) geomorphic parameters data arra\n",
    "    dbfksegID -- (int) segment ID of fake (ghost) node at network downstream boundary \n",
    "    z_all -- (dict) adjusted altitude dictionary with placeholder values to be replaced\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    z_all -- (dict) adjusted altitude dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    for x in range(mx_jorder, -1, -1):\n",
    "        for head_segment, reach in ordered_reaches[x]:\n",
    "            seg_list = reach[\"segments_list\"]\n",
    "            ncomp = reach[\"number_segments\"]\n",
    "            for seg in range(0, ncomp):\n",
    "                segID = seg_list[seg]\n",
    "                if seg == ncomp - 1 and seg_list.count(dbfksegID) == 0:\n",
    "                    # At junction, the altitude of fake segment (=bottom node)  of an upstream reach\n",
    "                    # is equal to that of the first segment (=top node) of the downstream reach\n",
    "\n",
    "                    # head segment id of downstream reach from a junction\n",
    "                    dsrchID = reach[\"downstream_head_segment\"]\n",
    "\n",
    "                    idx_dsrchID = np.where(geo_index == dsrchID)\n",
    "                    idx_alt = np.where(geo_cols == \"alt\")\n",
    "                    z_all[segID][\"adj.alt\"][0] = geo_data[idx_dsrchID, idx_alt]\n",
    "\n",
    "                elif seg == ncomp - 1 and seg_list.count(dbfksegID) > 0:\n",
    "                    # Terminal downstream fakesegment\n",
    "                    ## AD HOC: need to be corrected later\n",
    "                    segID2 = seg_list[seg - 1]\n",
    "                    idx_segID2 = np.where(geo_index == segID2)\n",
    "                    idx_so = np.where(geo_cols == \"s0\")\n",
    "                    idx_dx = np.where(geo_cols == \"dx\")\n",
    "\n",
    "                    So = geo_data[idx_segID2, idx_so]\n",
    "                    dx = geo_data[idx_segID2, idx_dx]\n",
    "                    z_all[segID][\"adj.alt\"][0] = z_all[segID2][\"adj.alt\"][0] - So * dx\n",
    "                else:\n",
    "                    idx_segID = np.where(geo_index == segID)\n",
    "                    idx_alt = np.where(geo_cols == \"alt\")\n",
    "                    z_all[segID][\"adj.alt\"][0] = geo_data[idx_segID, idx_alt]\n",
    "\n",
    "    return z_all\n",
    "\n",
    "\n",
    "def fp_mainstem_network_map(\n",
    "     mainstem_headseg_list,mx_jorder, ordered_reaches, rchbottom_reaches, nrch_g, frnw_col, dbfksegID, pynw\n",
    "):\n",
    "    \"\"\"\n",
    "    Channel network mapping between Python and Fortran\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mainstem_headseg_list -- (int) a list of link IDs of headsegs of related mainstem reaches \n",
    "    mx_jorder -- (int) maximum network reach order\n",
    "    ordered_reaches -- (dict) reaches and reach metadata by junction order\n",
    "    rchbottom_reaches -- (dict) reaches and reach metadata keyed by reach tail segment\n",
    "    nrch_g -- (int) number of reaches in the network\n",
    "    frnw_col -- (int) number of columns in the fortran network map\n",
    "    dbfskegID -- (str) segment ID of fake (ghost) node at network downstream boundary \n",
    "    pynw -- (dict) ordered reach head segments\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    frnw_g -- (nparray of int) Fortran-Python network mapping array\n",
    "    \"\"\"\n",
    "\n",
    "    #  Store headwater reach and upstream reaches above a junction\n",
    "    #  as well as downstream reach after a junction\n",
    "    #  into python-extension-fortran variables.\n",
    "    frnw_g = np.zeros((nrch_g, frnw_col), dtype=int)\n",
    "    frj = -1\n",
    "    for x in range(mx_jorder, -1, -1):\n",
    "        for head_segment, reach in ordered_reaches[x]:\n",
    "            seg_list = reach[\"segments_list\"]\n",
    "            ncomp = reach[\"number_segments\"]\n",
    "            frj = frj + 1\n",
    "            frnw_g[frj, 0] = ncomp\n",
    "\n",
    "            if not reach[\"upstream_bottom_segments\"]:\n",
    "                # headwater reach\n",
    "                frnw_g[frj, 2] = 0  # the number of upstream reaches\n",
    "            else:\n",
    "                # reaches before a junction\n",
    "                nusrch = len(reach[\"upstream_bottom_segments\"])\n",
    "                frnw_g[frj, 2] = nusrch  # the number of upstream reaches\n",
    "                usrch_bseg_list = list(reach[\"upstream_bottom_segments\"])\n",
    "                usrch_hseg_mainstem_j=-100 # ini.value of frj* of reach on mainstem that is just upstream of the current reach of frj\n",
    "                i = 0\n",
    "                for usrch in range(0, nusrch):\n",
    "                    usrch_bseg_id = usrch_bseg_list[\n",
    "                        usrch\n",
    "                    ]  # upstream reach's bottom segment\n",
    "                    usrch_hseg_id = rchbottom_reaches[usrch_bseg_id][\"segments_list\"][0]\n",
    "                    # find Fortran js corresponding to individual usrchid\n",
    "                    for j, sid in pynw.items():\n",
    "                        if sid == usrch_hseg_id:\n",
    "                            i = i + 1\n",
    "                            frnw_g[frj, 2 + i] = j\n",
    "                            # find if the selected headseg ID of an upstream reach belong to mainstem segment\n",
    "                            if mainstem_headseg_list.count(usrch_hseg_id) > 0:\n",
    "                                usrch_hseg_mainstem_j=j\n",
    "                # store frj of mainstem headseg's reach in the just upstream of the current reach of frj\n",
    "                frnw_g[frj, 2 + nusrch + 1] = usrch_hseg_mainstem_j\n",
    "                            \n",
    "\n",
    "            if seg_list.count(dbfksegID) > 0:\n",
    "                # a reach where downstream boundary condition is set.\n",
    "                frnw_g[\n",
    "                    frj, 1\n",
    "                ] = -100  # head_segment ID that is in terminal downstream reach.\n",
    "                # That is, -100 indicates the reach of the head segment is\n",
    "                # terminal downstream reach where ds.bcond. happens.\n",
    "            else:\n",
    "                # reach after a junction\n",
    "                dsrch_hseg_id = reach[\"downstream_head_segment\"]\n",
    "                # fortran j index equivalent to dsrchID.\n",
    "                frnw_g[frj, 1] = [\n",
    "                    j for j, sid in pynw.items() if sid == dsrch_hseg_id[0]\n",
    "                ][0]\n",
    "\n",
    "    # Adust frnw_g element values according to Fortran-Python index relationship, that is Python i = Fortran i+1\n",
    "    for frj in range(0, nrch_g):\n",
    "        frnw_g[frj, 1] = frnw_g[frj, 1] + 1  # downstream reach index for frj reach\n",
    "        if frnw_g[frj, 2] > 0:\n",
    "            nusrch = frnw_g[frj, 2]\n",
    "            for i in range(0, nusrch+1):  #<- +1 is for additional column of frj of mainstem headseg's reach in the upstream of the current reach of frj\n",
    "                frnw_g[frj, 3 + i] = (\n",
    "                    frnw_g[frj, 3 + i] + 1\n",
    "                )  # upstream reach indicds for frj reach\n",
    "\n",
    "    return frnw_g\n",
    "\n",
    "\n",
    "def fp_chgeo_map(\n",
    "    mx_jorder, ordered_reaches, geo_cols, geo_index, geo_data, z_all, mxncomp_g, nrch_g\n",
    "):\n",
    "    \"\"\"\n",
    "    Channel geometry data mapping between Python and Fortran\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mx_jorder -- (int) maximum network reach order\n",
    "    ordered_reaches -- (dict) reaches and reach metadata by junction order\n",
    "    geo_cols -- (ndarray of strs) column headers for geomorphic parameters data array (geo_data)\n",
    "    geo_index -- (ndarray of int64s) row indices for geomorphic parameters data array (geo_data)\n",
    "    geo_data --(ndarray of float32s) geomorphic parameters data array\n",
    "    z_all -- (dict) adjusted altitude dictionary\n",
    "    mxncomp_g -- (int) maximum number of nodes in a reach\n",
    "    nrch_g -- (int) number of reaches in the network\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    z_ar_g -- (numpy of float64s) altitude (meters)\n",
    "    bo_ar_g -- (numpy of float64s) bottom width (meters)\n",
    "    traps_ar_g -- (numpy of float64s) sideslope (m/m)\n",
    "    tw_ar_g -- (numpy of float64s) top width (meters)\n",
    "    twcc_ar_g -- (numpy of float64s) top width of compound channel (meters)\n",
    "    mann_ar_g -- (numpy of float64s) manning's roughness (seconds/meters^1/3)\n",
    "    mancc_ar_g -- (numpy of float64s) manning's roughness compound channel (seconds/meters^(1/3))\n",
    "    so_ar_g -- (numpy of float64s) bottom slope (m/m)\n",
    "    dx_ar_g -- (numpy of float64s) segment length (meters)\n",
    "    \"\"\"\n",
    "\n",
    "    z_ar_g = np.zeros((mxncomp_g, nrch_g))\n",
    "    bo_ar_g = np.zeros((mxncomp_g, nrch_g))\n",
    "    traps_ar_g = np.zeros((mxncomp_g, nrch_g))\n",
    "    tw_ar_g = np.zeros((mxncomp_g, nrch_g))\n",
    "    twcc_ar_g = np.zeros((mxncomp_g, nrch_g))\n",
    "    mann_ar_g = np.zeros((mxncomp_g, nrch_g))\n",
    "    manncc_ar_g = np.zeros((mxncomp_g, nrch_g))\n",
    "    so_ar_g = np.zeros((mxncomp_g, nrch_g))\n",
    "    dx_ar_g = np.zeros((mxncomp_g, nrch_g))\n",
    "    frj = -1\n",
    "    for x in range(mx_jorder, -1, -1):\n",
    "        for head_segment, reach in ordered_reaches[x]:\n",
    "            seg_list = reach[\"segments_list\"]\n",
    "            ncomp = reach[\"number_segments\"]\n",
    "            frj = frj + 1\n",
    "            for seg in range(0, ncomp):\n",
    "                if seg == ncomp - 1:\n",
    "                    segID = seg_list[seg - 1]\n",
    "                else:\n",
    "                    segID = seg_list[seg]\n",
    "\n",
    "                idx_segID = np.where(geo_index == segID)\n",
    "\n",
    "                idx_par = np.where(geo_cols == \"bw\")\n",
    "                bo_ar_g[seg, frj] = geo_data[idx_segID, idx_par]\n",
    "\n",
    "                idx_par = np.where(geo_cols == \"cs\")\n",
    "                traps_ar_g[seg, frj] = geo_data[idx_segID, idx_par]\n",
    "\n",
    "                idx_par = np.where(geo_cols == \"tw\")\n",
    "                tw_ar_g[seg, frj] = geo_data[idx_segID, idx_par]\n",
    "\n",
    "                idx_par = np.where(geo_cols == \"twcc\")\n",
    "                twcc_ar_g[seg, frj] = geo_data[idx_segID, idx_par]\n",
    "\n",
    "                idx_par = np.where(geo_cols == \"n\")\n",
    "                mann_ar_g[seg, frj] = geo_data[idx_segID, idx_par]\n",
    "\n",
    "                idx_par = np.where(geo_cols == \"ncc\")\n",
    "                manncc_ar_g[seg, frj] = geo_data[idx_segID, idx_par]\n",
    "\n",
    "                idx_par = np.where(geo_cols == \"s0\")\n",
    "                so_ar_g[seg, frj] = geo_data[idx_segID, idx_par]\n",
    "\n",
    "                idx_par = np.where(geo_cols == \"dx\")\n",
    "                dx_ar_g[seg, frj] = geo_data[idx_segID, idx_par]\n",
    "\n",
    "                segID1 = seg_list[seg]\n",
    "                z_ar_g[seg, frj] = z_all[segID1][\"adj.alt\"][0]\n",
    "\n",
    "    return (\n",
    "        z_ar_g,\n",
    "        bo_ar_g,\n",
    "        traps_ar_g,\n",
    "        tw_ar_g,\n",
    "        twcc_ar_g,\n",
    "        mann_ar_g,\n",
    "        manncc_ar_g,\n",
    "        so_ar_g,\n",
    "        dx_ar_g,\n",
    "    )\n",
    "\n",
    "\n",
    "def fp_qlat_map(\n",
    "    mx_jorder,\n",
    "    ordered_reaches,\n",
    "    nts_ql_g,\n",
    "    geo_cols,\n",
    "    geo_index,\n",
    "    geo_data,\n",
    "    qlat_data,\n",
    "    qlat_g,\n",
    "):\n",
    "    \"\"\"\n",
    "    lateral inflow mapping between Python and Fortran\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mx_jorder -- (int) maximum network reach order\n",
    "    nts_ql_g -- (int) numer of qlateral timesteps\n",
    "    geo_cols -- (ndarray of strs) column headers for geomorphic parameters data array (geo_data)\n",
    "    geo_index -- (ndarray of int64) row indices for geomorphic parameters data array (geo_data)\n",
    "    geo_data -- (ndarray of float32) geomorphic parameters data array\n",
    "    qlat_data -- (ndarray of float32) qlateral data (m3/sec)\n",
    "    qlat_g -- (ndarray of float32) empty qlateral array to be filled\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    qlat_g -- (ndarray of float32) qlateral array (m3/sec/m)\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    data in qlat_g are normalized by segment length with units of m2/sec = m3/sec/m\n",
    "    \"\"\"\n",
    "\n",
    "    frj = -1\n",
    "    for x in range(mx_jorder, -1, -1):\n",
    "        for head_segment, reach in ordered_reaches[x]:\n",
    "            seg_list = reach[\"segments_list\"]\n",
    "            ncomp = reach[\"number_segments\"]\n",
    "            frj = frj + 1\n",
    "            for seg in range(0, ncomp):\n",
    "                segID = seg_list[seg]\n",
    "                for tsi in range(0, nts_ql_g):\n",
    "                    if seg < ncomp - 1:\n",
    "\n",
    "                        idx_segID = np.where(geo_index == segID)\n",
    "                        idx_par = np.where(geo_cols == \"dx\")\n",
    "\n",
    "                        tlf = qlat_data[idx_segID, tsi]  # [m^3/sec]\n",
    "                        dx = geo_data[idx_segID, idx_par]  # [meter]\n",
    "                        qlat_g[tsi, seg, frj] = tlf / dx  # [m^2/sec]\n",
    "\n",
    "                    else:\n",
    "                        qlat_g[\n",
    "                            tsi, seg, frj\n",
    "                        ] = 0.0  # seg=ncomp is actually for bottom node in Fotran code.\n",
    "                        # And, lateral flow enters between adjacent nodes.\n",
    "\n",
    "    return qlat_g\n",
    "\n",
    "\n",
    "def fp_ubcd_map(frnw_g, pynw, nts_ub_g, nrch_g, ds_seg, upstream_inflows):\n",
    "    \"\"\"\n",
    "    Upstream boundary condition mapping between Python and Fortran\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    frnw_g -- (nparray of int) Fortran-Python network mapping array\n",
    "    pynw -- (dict) ordered reach head segments\n",
    "    nrch_g -- (int) number of reaches in the network\n",
    "    ds_seg -- (ndarray of int64) row indices for downstream segments recieving flows in upstream_flows\n",
    "    upstream_inflows (ndarray of float32) upstream_inflows (m3/sec) to segments in ds_seg\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ubcd_g -- (ndarray of float32) upstream boundary data (m3/sec)\n",
    "    \"\"\"\n",
    "\n",
    "    ubcd_g = np.zeros((nts_ub_g, nrch_g))\n",
    "    frj = -1\n",
    "\n",
    "    #loop over every segment in network\n",
    "    for frj in range(nrch_g):\n",
    "\n",
    "        #if this is a head segment\n",
    "        if frnw_g[frj, 2] == 0:  # the number of upstream reaches is zero.\n",
    "            \n",
    "            head_segment = pynw[frj]\n",
    "            \n",
    "            if head_segment in set(ds_seg):\n",
    "                \n",
    "                idx_dssegID = np.where(np.asarray(list(set(ds_seg))) == head_segment)\n",
    "                for tsi in range(0, nts_ub_g):\n",
    "                    ubcd_g[tsi, frj] = upstream_inflows[idx_dssegID, tsi]  # [m^3/s]\n",
    "\n",
    "    return ubcd_g\n",
    "\n",
    "\n",
    "def fp_dbcd_map(usgsID2tw=None, usgssDT=None, usgseDT=None, usgspCd=None):\n",
    "    \"\"\"\n",
    "    Downststream boundary condition mapping between Python and Fortran using USGS stage observations\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    usgsID2tw -- (str) usgs site ID\n",
    "    usgssDT -- (str) start data request date (yyyy-mm-dd) \n",
    "    usgseDT -- (str) end data request date (yyyy-mm-dd) \n",
    "    usgspCd --  (list of str) usgs parameter code \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    nts_db_g -- (int) number of timesteps in downstream boundary data\n",
    "    dbcd_g -- (ndarray of float64) downstream boundary data (meters)\n",
    "    \"\"\"\n",
    "\n",
    "    # ** 1) downstream stage (here, lake elevation) boundary condition\n",
    "    # from nwis_client.iv import IVDataService\n",
    "    # install via: pip install hydrotools.nwis_client\n",
    "    if usgsID2tw:\n",
    "        try:\n",
    "            from hydrotools.nwis_client.iv import IVDataService\n",
    "        except ImportError as err:\n",
    "            print(err, end=\"... \")\n",
    "            print(\n",
    "                \"Please install hydrotools.nwis_client via: `pip install hydrotools.nwis_client`\"\n",
    "            )\n",
    "            raise  # ensures program exit by re-raising the error.\n",
    "\n",
    "        # from evaluation_tools.nwis_client.iv import IVDataService\n",
    "        # Retrieve streamflow and stage data from two sites\n",
    "        # Note: 1. Retrieved data all are based on UTC time zone (UTC is 4 hours ahead of Eastern Time during\n",
    "        #          daylight saving time and 5 hours ahead during standard time)\n",
    "        #       2. Retrieved data are always 1 hour ahead of stated startDT and 1 hour ahead of endDT,\n",
    "        #          where starDT or endDT equal to yyyy-mm-dd 00:00.\n",
    "        #       3. Also, retrieved data in 15 min so there are always four more data before startDT\n",
    "        #          and four less data before endDT.\n",
    "        #          For example, startDT='2018-08-01' and endDT='2018-09-01', then the retrieved data starts by\n",
    "        #          2018-07-31-23:00:00\n",
    "        #          2018-07-31-23:15:00\n",
    "        #          2018-07-31-23:30:00\n",
    "        #          2018-07-31-23:45:00\n",
    "        #          2018-08-01-00:00:00\n",
    "        #               .......\n",
    "        #          2018-08-31-22:00:00\n",
    "        #          2018-08-31-22:15:00\n",
    "        #          2018-08-31-22:30:00\n",
    "        #          2018-08-31-22:45:00\n",
    "        #          2018-08-31-23:00:00\n",
    "        #       4. '00060' for discharge [ft^3/s]\n",
    "        #          '00065' for stage [ft]\n",
    "        #          '62614' for Elevation, lake/res,NGVD29 [ft]\n",
    "        ivds = IVDataService()\n",
    "        observations_data = ivds.get(\n",
    "            sites=usgsID2tw,  # sites='01646500,0208758850',\n",
    "            startDT=usgssDT,  #'2018-08-01',\n",
    "            endDT=usgseDT,  #'2020-09-01',\n",
    "            # parameterCd='62614'\n",
    "            parameterCd=usgspCd,\n",
    "        )\n",
    "        nts_db_g = len(observations_data) - 4\n",
    "        # ** 4 is added to make data used here has its date time as from startDT 00:00 to (endDT-1day) 23:00, UTC\n",
    "        # ** usgs data at this site uses NGVD1929 feet datum while 'alt' of RouteLink uses NAD88 meter datum.\n",
    "        #  -> Has to convert accordingly !!!!\n",
    "        #\n",
    "        # source: https://pubs.usgs.gov/sir/2010/5040/section.html\n",
    "        # Over most USGS study area it is used that NGVD = NAVD88 - 3.6 feet\n",
    "        dbcd_g = np.zeros(nts_db_g)\n",
    "        for tsi in range(0, nts_db_g):\n",
    "            i = tsi + 4\n",
    "            dmy = observations_data.iloc[i, 4]\n",
    "            dbcd_g[tsi] = 0.3048 * (\n",
    "                dmy + 3.6\n",
    "            )  # accuracy with +-0.5feet for 95 percent of USGS study area.\n",
    "            # 0.3048 to covert ft to meter. [meter]\n",
    "    else:\n",
    "        nts_db_g = 1\n",
    "        dbcd_g = -np.ones(nts_db_g)\n",
    "        \n",
    "    return nts_db_g, dbcd_g\n",
    "\n",
    "def fp_naturalxsec_map(\n",
    "        mainstem_headseg_list, inland_bathyNC, comid_bathy, geo_index, geo_cols, geo_data, mxncomp_g, nrch_g):\n",
    "    \"\"\"\n",
    "    natural cross section mapping between Python and Fortran using eHydro_ned_cross_sections data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mainstem_headseg_list -- (int) a list of link IDs of headsegs of related mainstem reaches \n",
    "    inland_bathyNC --  bathymetry NC data of channel cross section\n",
    "    geo_index -- (ndarray of int64s) row indices for geomorphic parameters data array (geo_data)\n",
    "    mxncomp_g -- (int) maximum number of nodes in a reach\n",
    "    nrch_g -- (int) number of reaches in the network\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x_bathy_g -- (numpy of float64s) lateral distance of bathy data points\n",
    "    z_bathy_g -- (numpy of float64s) elevation of bathy data points\n",
    "    size_bathy_g -- (integer) the nubmer of bathy data points of each cross section\n",
    "    mxnbathy_g -- (integer) maximum size of bathy data points\n",
    "    \"\"\"    \n",
    "    # take only related data from bathy NC file\n",
    "    inland_bathyDF = pd.DataFrame()\n",
    "    inland_bathyDF['comid'] =  pd.DataFrame(np.ma.filled(inland_bathyNC['comid'][:]))\n",
    "    # this is lateral distance from x=0 where the NWM line crosses the cross section later line. \n",
    "    # For left side of x=0 (when looking upstream-to-downstream), the lateral distance takes negative values \n",
    "    # for left side of main channel or left floodplains whiel positive for right side of main ch. or right floodplains.\n",
    "    inland_bathyDF['x_bathy'] =  pd.DataFrame(np.ma.filled(inland_bathyNC['xid_d'][:]))\n",
    "    inland_bathyDF['z_bathy'] =   pd.DataFrame(np.ma.filled(inland_bathyNC['z'][:]))    \n",
    "    \n",
    "    # find maximum size of x or z bathy data\n",
    "    sizelist=[]\n",
    "    ncomid= len(comid_bathy)\n",
    "    for i in range(0,ncomid): # for bathy data of arbitarily selected three segments\n",
    "        inland_bathyDF_subset = inland_bathyDF[inland_bathyDF['comid'] == comid_bathy[i]]    \n",
    "        size= inland_bathyDF_subset['x_bathy'].size\n",
    "        sizelist.append(size)\n",
    "    mxnbathy_g=max(sizelist)\n",
    "\n",
    "    x_bathy_g = np.zeros((mxnbathy_g, mxncomp_g, nrch_g))\n",
    "    z_bathy_g = np.zeros((mxnbathy_g, mxncomp_g, nrch_g))\n",
    "    size_bathy_g= np.zeros((mxncomp_g, nrch_g), dtype=int)\n",
    "    \n",
    "    frj = -1\n",
    "    for x in range(mx_jorder, -1, -1):\n",
    "        for head_segment, reach in ordered_reaches[x]:\n",
    "            seg_list = reach[\"segments_list\"]\n",
    "            ncomp = reach[\"number_segments\"]\n",
    "            frj = frj + 1\n",
    "            for seg in range(0,ncomp):\n",
    "                if seg==ncomp-1 and x > 0:\n",
    "                    #In node-configuration, bottom node takes bathy of the first segment of the downtream reach\n",
    "                    # except TW reach where the bottom node bathy is interpolated by bathy of the last segment with so*0.5*dx of \n",
    "                    segID= reach[\"downstream_head_segment\"]\n",
    "                else:\n",
    "                    # In node configuration, for example, for 2 segments of a reach, \n",
    "                    # 1st node(=top node) takes bathy of the first segment and\n",
    "                    # 2nd node takes bathy of the second segment\n",
    "                    # 3rd node takes bathy of, as explained right above, the firt segment \n",
    "                    segID= seg_list[seg]\n",
    "                \n",
    "                #idx_segID = np.where(geo_index == segID)\n",
    "                    \n",
    "    ## **** for now, bathy data here doesn't cover Cape fear river we're experimenting with. So, we picked\n",
    "    ## **** arbitrarily three comid from the bathy NC data and get the bathy data to pass to three segments\n",
    "    ## **** we're considering now. Basically, three mainstem reaches with each having only one segment.\n",
    "                \n",
    "                if mainstem_headseg_list.count(segID) > 0:  \n",
    "                # when selected segID is mainstem:\n",
    "                    \n",
    "                    ## **** all hypothetical coding\n",
    "                    if x==2 and seg==0:\n",
    "                        idx_comid=0\n",
    "                    if x==2 and seg==1:\n",
    "                        idx_comid=1\n",
    "                    if x==1 and seg==0:\n",
    "                        idx_comid=1\n",
    "                    if x==1 and seg==1:\n",
    "                        idx_comid=2\n",
    "                    if x==0 and seg==0:\n",
    "                        idx_comid=2\n",
    "                    if x==0 and seg==1:\n",
    "                        #when tail water node, z_bathy will be adjusted by so*dx of related segment\n",
    "                        idx_comid=2                                      \n",
    "                    \n",
    "                    inland_bathyDF_subset = inland_bathyDF[inland_bathyDF['comid'] == comid_bathy[idx_comid]]\n",
    "                    size_bathy_g[seg, frj]= inland_bathyDF_subset['x_bathy'].size\n",
    "                    \n",
    "                    for idp in range(0, size_bathy_g[seg, frj]):\n",
    "                        x_bathy_g[idp, seg, frj]  = inland_bathyDF_subset [['x_bathy']].iloc[idp]\n",
    "                        z_bathy_g[idp, seg, frj] =  inland_bathyDF_subset [['z_bathy']].iloc[idp]  \n",
    "                        \n",
    "                if seg == ncomp - 1 and seg_list.count(dbfksegID) > 0:\n",
    "                    # At tailwater bottom node, z_bathy need to be adjusted by so*dx of the last segment\n",
    "                    segID2 = seg_list[seg - 1]\n",
    "                    idx_segID = np.where(geo_index == segID2)\n",
    "                    idx_so = np.where(geo_cols == \"s0\")\n",
    "                    idx_dx = np.where(geo_cols == \"dx\")\n",
    "\n",
    "                    So = geo_data[idx_segID2, idx_so]\n",
    "                    dx = geo_data[idx_segID2, idx_dx]\n",
    "                    \n",
    "                    for idp in range(0, size_bathy_g[seg, frj]):\n",
    "                        z_bathy_g[idp, seg, frj] = z_bathy_g[idp, seg, frj] - So * dx    \n",
    "\n",
    "   \n",
    "    return x_bathy_g, z_bathy_g, size_bathy_g, mxnbathy_g\n",
    "\n",
    "\n",
    "def diffusive_input_data_v01(\n",
    "    tw,\n",
    "    connections,\n",
    "    rconn,\n",
    "    reach_list,\n",
    "    mainstem_headseg_list,\n",
    "    q_wrf_data,    \n",
    "    diffusive_parameters,\n",
    "    geo_cols,\n",
    "    geo_index,\n",
    "    geo_data,\n",
    "    qlat_data,\n",
    "    initial_conditions,\n",
    "    upstream_results,\n",
    "    qts_subdivisions,\n",
    "    nsteps,\n",
    "    dt,\n",
    "    lake_segs,\n",
    "    wbody_params,\n",
    "    comid_bathy,\n",
    "    inland_bathyNC,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build input data objects for diffusive wave model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tw -- (int) Tailwater segment ID\n",
    "    connections -- (dict) donwstream connections for each segment in the network\n",
    "    rconn -- (dict) upstream connections for each segment in the network\n",
    "    reach_list -- (list of lists) lists of segments comprising different reaches in the network\n",
    "    diffusive_parametters -- (dict) Diffusive wave model parameters\n",
    "    geo_cols -- (ndarray of strs) column headers for geomorphic parameters data array (geo_data)\n",
    "    geo_index -- (ndarray of int64s) row indices for geomorphic parameters data array (geo_data)\n",
    "    geo_data --(ndarray of float32s) geomorphic parameters data array\n",
    "    qlat_data -- (ndarray of float32) qlateral data (m3/sec)\n",
    "    initial_conditions -- (ndarray of float32) initial flow (m3/sec) and depth (m above ch bottom) states for network nodes\n",
    "    upstream_results -- (dict) with values of 1d arrays upstream flow, velocity, and depth   \n",
    "    qts_subdivisions -- (int) number of qlateral timestep subdivisions \n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    diff_ins -- (dict) formatted inputs for diffusive wave model\n",
    "    \"\"\"\n",
    "    \n",
    "    dt_ql_g = 3600 #dt * qts_subdivisions    # lateral inflow timestep (sec)    \n",
    "    dt_ub_g = 3600 #dt    # upstream boundary condition timestep (sec)    \n",
    "    dt_db_g = 3600 #dt * qts_subdivisions    # downstream boundary condition timestep (sec)    \n",
    "    saveinterval_tu = 60.0    # time interval at which flow and depth simulations are written out by Tulane diffusive model    \n",
    "    saveinterval_cnt = 12*dt  #* qts_subdivisions    # time interval at which depth is written out by cnt model\n",
    "    dtini_g = dt    # simulation time step (for cn-mod, it changes but fixed for cnt and cnx)\n",
    "    dt_qtrib_g = 60.0  #3600.0    #tributary (including mainstem upstream boundary) data time step [sec]\n",
    "    t0_g = 0.0     # simulation start hr **set to zero for Fortran computation\n",
    "    tfin_g = 72.0  # (dt * nsteps)/60/60 # [hr]\n",
    "    \n",
    "    # USGS data related info.\n",
    "    #usgsID = diffusive_parameters.get(\"usgsID\", None)\n",
    "    #seg2usgsID = diffusive_parameters.get(\"link2usgsID\", None)\n",
    "    #usgssDT = diffusive_parameters.get(\"usgs_start_date\", None)\n",
    "    #usgseDT = diffusive_parameters.get(\"usgs_end_date\", None)\n",
    "    #usgspCd = diffusive_parameters.get(\"usgs_parameterCd\", None)\n",
    "    \n",
    "    # CNX: store the time variable values in the above to an array\n",
    "    '''\n",
    "    timestep_ar_g = np.zeros(8)\n",
    "    timestep_ar_g[0]= dtini_g\n",
    "    timestep_ar_g[1]= t0_g\n",
    "    timestep_ar_g[2]= tfin_g\n",
    "    timestep_ar_g[3]= 0.0 # not used  \n",
    "    timestep_ar_g[4]= dt_ql_g\n",
    "    timestep_ar_g[5]= dt_ub_g\n",
    "    timestep_ar_g[6]= dt_db_g\n",
    "    timestep_ar_g[7]= dt_qtrib_g   \n",
    "    '''\n",
    "    '''\n",
    "    # CN-mod: store the time variable values in the above to an array\n",
    "    timestep_ar_g = np.zeros(8)\n",
    "    timestep_ar_g[0]= dtini_g\n",
    "    timestep_ar_g[1]= t0_g\n",
    "    timestep_ar_g[2]= tfin_g\n",
    "    timestep_ar_g[3]= saveinterval_tu\n",
    "    timestep_ar_g[4]= dt_ql_g\n",
    "    timestep_ar_g[5]= dt_ub_g\n",
    "    timestep_ar_g[6]= dt_db_g\n",
    "    timestep_ar_g[7]= dt_qtrib_g   \n",
    "    '''\n",
    "    # CNT: store the time variable values in the above to an array\n",
    "    timestep_ar_g = np.zeros(8)\n",
    "    timestep_ar_g[0]= dtini_g\n",
    "    timestep_ar_g[1]= t0_g\n",
    "    timestep_ar_g[2]= tfin_g\n",
    "    timestep_ar_g[3]= saveinterval_cnt\n",
    "    timestep_ar_g[4]= dt_ql_g\n",
    "    timestep_ar_g[5]= dt_ub_g\n",
    "    timestep_ar_g[6]= dt_db_g\n",
    "    timestep_ar_g[7]= dt_qtrib_g   \n",
    "    #'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    # diffusive parameters\n",
    "    #cfl_g = diffusive_parameters.get(\"courant_number_upper_limit\", None)\n",
    "    #theta_g = diffusive_parameters.get(\"theta_parameter\", None)\n",
    "    #tzeq_flag_g = diffusive_parameters.get(\"chgeo_computation_flag\", None)\n",
    "    #y_opt_g = diffusive_parameters.get(\"water_elevation_computation_flag\", None)\n",
    "    #so_llm_g = diffusive_parameters.get(\"bed_slope_lower_limit\", None) \n",
    "    \n",
    "    # CNX Parameters\n",
    "    '''   \n",
    "    paradim=6 \n",
    "    para_ar_g= np.zeros(paradim)\n",
    "    para_ar_g[0]= 0.95 #lower limit of Courant number.\n",
    "    para_ar_g[1]= 0.05  # lower limit of celerity.\n",
    "    para_ar_g[2]= 0.002    # lower limit of discharge.\n",
    "    para_ar_g[3]= 0.00001    # lower limit of channel bed slope.\n",
    "    para_ar_g[4]= 12 # upper limit of the number of uniformly distributed sub-nodes, including ghost nodes, on each stream segment.\n",
    "    para_ar_g[5]= 2  # number of sub-nodes added to existing uniformly distributed sub-nodes, used to provide adequate discharge downstream boundary condition. \n",
    "    '''\n",
    "    '''\n",
    "    # CN-mod parameters\n",
    "    paradim=10\n",
    "    para_ar_g= np.zeros(paradim)\n",
    "    para_ar_g[0]= 0.95    # Courant number (default: 0.95)\n",
    "    para_ar_g[1]= 0.5     # lower limit of celerity (default: 0.5)\n",
    "    para_ar_g[2]= 50.0    # lower limit of diffusivity (default: 50)\n",
    "    para_ar_g[3]= 5000.0  # upper limit of diffusivity (default: 1000)\n",
    "    para_ar_g[4]= -15.0   # lower limit of dimensionless diffusivity, used to determine b/t normal depth and diffusive depth\n",
    "    para_ar_g[5]= -10.0   #upper limit of dimensionless diffusivity, used to determine b/t normal depth and diffusive depth\n",
    "    para_ar_g[6]= 1.0     # 0:run Bisection to compute water level; 1: Newton Raphson (default: 1.0)\n",
    "    para_ar_g[7]= 0.02831   # lower limit of discharge (default: 0.02831 cms)\n",
    "    para_ar_g[8]= 0.0001    # lower limit of channel bed slope (default: 0.0001)\n",
    "    para_ar_g[9]= 1.0     # weight in numerically computing 2nd derivative: 0: explicit, 1: implicit (default: 1.0)\n",
    "    '''    \n",
    "    # CNT parameters\n",
    "    paradim=9\n",
    "    para_ar_g= np.zeros(paradim)\n",
    "    para_ar_g[0]= 0.5    # lower limit of celerity\n",
    "    para_ar_g[1] = 50.0   # lower limit of diffusivity\n",
    "    para_ar_g[2] = 400.0  # upper limit of diffusivity\n",
    "    para_ar_g[3] = 0.1    # lower limit of dimensionless space step, used to reduce ocillation of hydrograph\n",
    "    para_ar_g[4] = 0.3    # lower limit of dimensionless time step, used to reduce ociallation of hydrograph\n",
    "    para_ar_g[5] = 2  # the number of ghost time node, used to get adequate dischage boundary condition in time.\n",
    "    para_ar_g[6] = 0.02831 # lower limit of discharge\n",
    "    para_ar_g[7] = 0.0001 # lower limit of channel bed slope\n",
    "    para_ar_g[8] =  3  # 1: bisection, 2: simple iterative with contribution from dU/dX, 3: Newton Raphson for water depth\n",
    "\n",
    "    # number of reaches in network\n",
    "    nrch_g = len(reach_list)\n",
    "\n",
    "    # maximum number of nodes in a reach\n",
    "    mxncomp_g = 0\n",
    "    for r in reach_list:\n",
    "        nnodes = len(r) + 1\n",
    "        if nnodes > mxncomp_g:\n",
    "            mxncomp_g = nnodes\n",
    "    \n",
    "    ds_seg = []\n",
    "    offnet_segs = []\n",
    "    upstream_flow_array = np.zeros((len(ds_seg), nsteps+1))\n",
    "    if upstream_results:\n",
    "        \n",
    "        # create a list of segments downstream of offnetwork upstreams [ds_seg]\n",
    "        # and a list of offnetwork upstream segments [offnet_segs]\n",
    "        inv_map = nhd_network.reverse_network(rconn)\n",
    "        for seg in upstream_results:\n",
    "            ds_seg.append(inv_map[seg][0])\n",
    "            offnet_segs.append(seg)\n",
    "        \n",
    "        # populate an array of upstream flows (boundary condtions)\n",
    "        upstream_flow_array = np.zeros((len(set(ds_seg)), nsteps+1))\n",
    "        for j, seg in enumerate(set(ds_seg)):\n",
    "            \n",
    "            # offnetwork-upstream connections\n",
    "            us_segs = rconn[seg]\n",
    "            \n",
    "            # sum upstream flows and initial conditions\n",
    "            usq = np.zeros((len(us_segs), nsteps))\n",
    "            us_iniq = 0\n",
    "            for k, s in enumerate(us_segs):\n",
    "                usq[k] = upstream_results[s]['results'][::3]\n",
    "                \n",
    "                if s in lake_segs:\n",
    "                    # initial conditions from wbody_param array\n",
    "                    idx_segID = np.where(np.asarray(lake_segs) == s)\n",
    "                    us_iniq += wbody_params[idx_segID,9]\n",
    "                else:\n",
    "                    # initial conditions from initial_conditions array\n",
    "                    idx_segID = np.where(geo_index == s)\n",
    "                    us_iniq += initial_conditions[idx_segID,0]\n",
    "            \n",
    "            # write upstream flows to upstream_flow_array\n",
    "            upstream_flow_array[j,1:] = np.sum(usq, axis = 0)\n",
    "            upstream_flow_array[j,0] = us_iniq\n",
    "    \n",
    "    # Order reaches by junction depth\n",
    "    path_func = partial(nhd_network.split_at_waterbodies_and_junctions, set(offnet_segs), rconn)\n",
    "    tr = nhd_network.dfs_decomposition_depth_tuple(rconn, path_func)    \n",
    "    \n",
    "    jorder_reaches = sorted(tr, key=lambda x: x[0])\n",
    "    mx_jorder = max(jorder_reaches)[0]  # maximum junction order of subnetwork of TW\n",
    "    \n",
    "    ordered_reaches = {}\n",
    "    rchhead_reaches = {}\n",
    "    rchbottom_reaches = {}\n",
    "    z_all = {}\n",
    "    for o, rch in jorder_reaches:\n",
    "\n",
    "        # add one more segment(fake) to the end of a list of segments to account for node configuration.\n",
    "        fksegID = int(str(rch[-1]) + str(2))\n",
    "        rch.append(fksegID)\n",
    "\n",
    "        # additional segment(fake) to upstream bottom segments\n",
    "        if any(j in rconn[rch[0]] for j in offnet_segs):\n",
    "            fk_usbseg = []\n",
    "        else:\n",
    "            fk_usbseg = [int(str(x) + str(2)) for x in rconn[rch[0]]]            \n",
    "\n",
    "        if o not in ordered_reaches:\n",
    "            ordered_reaches.update({o: []})\n",
    "        ordered_reaches[o].append(\n",
    "            [\n",
    "                rch[0],\n",
    "                {\n",
    "                    \"number_segments\": len(rch),\n",
    "                    \"segments_list\": rch,\n",
    "                    \"upstream_bottom_segments\": fk_usbseg,\n",
    "                    \"downstream_head_segment\": connections[rch[-2]],\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if rch[0] not in rchhead_reaches:\n",
    "            # a list of segments for a given head segment\n",
    "            rchhead_reaches.update(\n",
    "                {rch[0]: {\"number_segments\": len(rch), \"segments_list\": rch}}\n",
    "            )\n",
    "            # a list of segments for a given bottom segment\n",
    "            rchbottom_reaches.update(\n",
    "                {rch[-1]: {\"number_segments\": len(rch), \"segments_list\": rch}}\n",
    "            )\n",
    "        # for channel altitude adjustment\n",
    "        z_all.update({seg: {\"adj.alt\": np.zeros(1)} for seg in rch})\n",
    "\n",
    "        # cahnnel geometry data\n",
    "        a = np.where(geo_cols == \"cs\")\n",
    "        geo_data[:, a] = 1.0 / geo_data[:, a]\n",
    "    \n",
    "\n",
    "    # --------------------------------------------------------------------------------------\n",
    "    #                                 Step 0-3\n",
    "    #    Adjust altitude so that altitude of the last sement of a reach is equal to that\n",
    "    #    of the first segment of its downstream reach right after their common junction.\n",
    "    # --------------------------------------------------------------------------------------\n",
    "    dbfksegID = int(str(tw) + str(2))\n",
    "\n",
    "    adj_alt1(\n",
    "        mx_jorder, ordered_reaches, geo_cols, geo_index, geo_data, dbfksegID, z_all\n",
    "    )\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------\n",
    "    #                                 Step 0-4\n",
    "    #     Make Fortran-Python channel network mapping variables.\n",
    "    # --------------------------------------------------------------------------------------\n",
    "\n",
    "    # build a list of head segments in descending reach order [headwater -> tailwater]\n",
    "    pynw = {}\n",
    "    frj = -1\n",
    "    for x in range(mx_jorder, -1, -1):\n",
    "        for head_segment, reach in ordered_reaches[x]:\n",
    "            frj = frj + 1\n",
    "            pynw[frj] = head_segment\n",
    "    \n",
    "\n",
    "    frnw_col = diffusive_parameters.get(\"fortran_nework_map_col_number\", None)\n",
    "    frnw_g = fp_mainstem_network_map(\n",
    "        mainstem_headseg_list, mx_jorder, ordered_reaches, rchbottom_reaches, nrch_g, frnw_col, dbfksegID, pynw\n",
    "    )\n",
    "\n",
    "    # covert data type from integer to float for frnw\n",
    "    dfrnw_g = np.zeros((nrch_g, frnw_col), dtype=float)\n",
    "    for j in range(0, nrch_g):\n",
    "        for col in range(0, frnw_col):\n",
    "            dfrnw_g[j, col] = float(frnw_g[j, col])\n",
    "    \n",
    "    np.savetxt(\"./temp/frnw_ar.txt\", frnw_g, fmt='%10i')\n",
    "    #np.savetxt(\"./temp/pynw_ar.txt\", pynw, fmt='%20i')\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    #                              Step 0-5\n",
    "    #                  Prepare channel geometry data\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    (\n",
    "        z_ar_g,\n",
    "        bo_ar_g,\n",
    "        traps_ar_g,\n",
    "        tw_ar_g,\n",
    "        twcc_ar_g,\n",
    "        mann_ar_g,\n",
    "        manncc_ar_g,\n",
    "        so_ar_g,\n",
    "        dx_ar_g,\n",
    "    ) = fp_chgeo_map(\n",
    "        mx_jorder,\n",
    "        ordered_reaches,\n",
    "        geo_cols,\n",
    "        geo_index,\n",
    "        geo_data,\n",
    "        z_all,\n",
    "        mxncomp_g,\n",
    "        nrch_g,\n",
    "    )\n",
    "    # saved txt file has row for segment and colunum for frj\n",
    "    np.savetxt(\"./temp/z_ar.txt\", z_ar_g, fmt='%15.5f')\n",
    "    np.savetxt(\"./temp/bo_ar.txt\", bo_ar_g, fmt='%15.5f')\n",
    "    np.savetxt(\"./temp/traps_ar.txt\", traps_ar_g, fmt='%15.5f')\n",
    "    np.savetxt(\"./temp/tw_ar.txt\", tw_ar_g, fmt='%15.5f')\n",
    "    np.savetxt(\"./temp/twcc_ar.txt\", twcc_ar_g, fmt='%15.5f')\n",
    "    np.savetxt(\"./temp/mann_ar.txt\", mann_ar_g, fmt='%15.5f')\n",
    "    np.savetxt(\"./temp/manncc_ar.txt\", manncc_ar_g, fmt='%15.5f')\n",
    "    np.savetxt(\"./temp/so_ar.txt\", so_ar_g, fmt='%15.6f') \n",
    "    np.savetxt(\"./temp/dx_ar.txt\", dx_ar_g, fmt='%15.5f')   \n",
    "    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    #                              Step 0-6\n",
    "    #                  Prepare initial conditions data\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    output_path='./temp'\n",
    "    \n",
    "    iniq = np.zeros((mxncomp_g, nrch_g))\n",
    "    frj = -1\n",
    "    for x in range(mx_jorder, -1, -1):\n",
    "        for head_segment, reach in ordered_reaches[x]:\n",
    "            seg_list = reach[\"segments_list\"]\n",
    "            ncomp = reach[\"number_segments\"]\n",
    "            frj = frj + 1\n",
    "            for seg in range(0, ncomp):\n",
    "                if seg == ncomp - 1:\n",
    "                    segID = seg_list[seg - 1]\n",
    "                else:\n",
    "                    segID = seg_list[seg]\n",
    "                    \n",
    "                idx_segID = np.where(geo_index == segID)\n",
    "                iniq[seg, frj] = initial_conditions[idx_segID, 0]\n",
    "                if iniq[seg, frj]<0.0001:\n",
    "                    iniq[seg, frj]=0.0001\n",
    "    \n",
    "    frj= -1\n",
    "    with open(\"./temp/iniq_ar.txt\",'a') as pyqini:    \n",
    "        for x in range(mx_jorder,-1,-1):   \n",
    "            for head_segment, reach in ordered_reaches[x]:                  \n",
    "                seg_list= reach[\"segments_list\"]\n",
    "                ncomp= reach[\"number_segments\"]             \n",
    "                frj= frj+1     \n",
    "                for seg in range(0,ncomp):                               \n",
    "                    segID= seg_list[seg]                  \n",
    "                    dmy1= iniq[seg, frj]\n",
    "                    pyqini.write(\"%s %s %s\\n\" %\\\n",
    "                                (str(frj+1), str(seg+1), str(dmy1)) )                   \n",
    "                                # <- +1 is added to frj for accommodating Fortran indexing. \n",
    "    diffusive_utils_mainstem_naturalxsec\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    #                              Step 0-7\n",
    "\n",
    "    #                  Prepare lateral inflow data\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    nts_ql_g = (\n",
    "        int((tfin_g - t0_g) * 3600.0 / dt_ql_g)\n",
    "    )  # the number of the entire time steps of lateral flow data\n",
    "\n",
    "    qlat_g = np.zeros((nts_ql_g, mxncomp_g, nrch_g))\n",
    "\n",
    "    fp_qlat_map(\n",
    "        mx_jorder,\n",
    "        ordered_reaches,\n",
    "        nts_ql_g,\n",
    "        geo_cols,\n",
    "        geo_index,\n",
    "        geo_data,\n",
    "        qlat_data,\n",
    "        qlat_g,\n",
    "    )\n",
    "       \n",
    "    frj= -1\n",
    "    with open(\"./temp/qlat_ar.txt\",'a') as pyql:\n",
    "    #if 1==1:\n",
    "        for x in range(mx_jorder,-1,-1):   \n",
    "            for head_segment, reach in ordered_reaches[x]:                  \n",
    "                seg_list= reach[\"segments_list\"]\n",
    "                ncomp= reach[\"number_segments\"]             \n",
    "                frj= frj+1     \n",
    "                for seg in range(0,ncomp):                               \n",
    "                    segID= seg_list[seg]\n",
    "                    for tsi in range (0,nts_ql_g):\n",
    "                        t_min= dt_ql_g/60.0*float(tsi)                        \n",
    "                        dmy1= qlat_g[tsi, seg, frj]\n",
    "                        pyql.write(\"%s %s %s %s\\n\" %\\\n",
    "                                (str(frj+1), str(seg+1), str(t_min), str(dmy1)) )                   \n",
    "                                # <- +1 is added to frj for accommodating Fortran indexing. \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    #                              Step 0-8\n",
    "\n",
    "    #       Prepare upstream boundary (top segments of head basin reaches) data\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    #nts_ub_g = upstream_flow_array.shape[1]\n",
    "    nts_ub_g = int((tfin_g - t0_g) * 3600.0 / dt_ub_g)\n",
    "    ubcd_g = fp_ubcd_map(frnw_g, pynw, nts_ub_g, nrch_g, ds_seg, upstream_flow_array)\n",
    "\n",
    "\n",
    "        \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    #                              Step 0-9\n",
    "\n",
    "    #       Prepare downstrea boundary (bottom segments of TW reaches) data\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    '''\n",
    "    if seg2usgsID:\n",
    "        if tw in seg2usgsID:\n",
    "            ipos = seg2usgsID.index(tw)\n",
    "            usgsID2tw = usgsID[ipos]\n",
    "        else:\n",
    "            usgsID2tw=None\n",
    "    else:\n",
    "        usgsID2tw=None\n",
    "    \n",
    "    nts_db_g, dbcd_g = fp_dbcd_map(usgsID2tw, usgssDT, usgseDT, usgspCd)\n",
    "    '''\n",
    "    nts_db_g = 1\n",
    "    dbcd_g = -np.ones(nts_db_g)   \n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------\n",
    "    #                              Step 0-9-2\n",
    "\n",
    "    #       Prepare tributary q time series data generated by MC that flow into a juction boundary  \n",
    "    # ---------------------------------------------------------------------------------------------\n",
    "    #dt_qtrib_g=3600.0 # MC chrout file time step in [sec]  ** TO DO: move to yaml or else.\n",
    "    nts_qtrib_g = int((tfin_g - t0_g) * 3600.0 / dt_qtrib_g)\n",
    "    \n",
    "    qtrib_g = np.zeros((nts_qtrib_g, nrch_g))\n",
    "    frj = -1\n",
    "    for x in range(mx_jorder, -1, -1):\n",
    "        for head_segment, reach in ordered_reaches[x]:\n",
    "            frj = frj + 1\n",
    "            if mainstem_headseg_list.count(head_segment) == 0:                \n",
    "                idx_trib = np.where(geo_index == head_segment)               \n",
    "                #qtrib_g[:,frj]= q_wrf_data[idx_trib, 0:nts_qtrib_g] \n",
    "                qtrib_g[:,frj]= 0.0    #test  \n",
    "                #qtrib=[value for count, value in enumerate(q_wrf_data[idx_trib]) if count<nts_qtrib_g]\n",
    "                #qtrib2=np.asarray(qtrib)\n",
    "                #qtrib_g[:,frj]= qtrib2\n",
    "                #for i in range(0,nts_qtrib_g):\n",
    "                #    qtrib_g[i,frj]=q_wrf_data[idx_trib,i]\n",
    "    # synthetic inflow at mainstem upper boundary\n",
    "    import math\n",
    "    qsi= 100.0\n",
    "    wsi= 80.0\n",
    "    zsi= 0.6\n",
    "    for n in range(0,nts_qtrib_g):\n",
    "        tmin= dt_qtrib_g/60.0*n\n",
    "        if n==0:\n",
    "            tmin= 0.1\n",
    "        qtrib_g[n,1]= qsi*math.exp(zsi*(2.0 - tmin/wsi - wsi/tmin))/((tmin/wsi)**(3.0/2.0))   \n",
    "    \n",
    "    frj= -1\n",
    "    with open(os.path.join(output_path,\"qtrib_ar.txt\"),'a') as pyqtrib:\n",
    "        for x in range(mx_jorder,-1,-1):   \n",
    "            for head_segment, reach in ordered_reaches[x]:                  \n",
    "                seg_list= reach[\"segments_list\"]\n",
    "                ncomp= reach[\"number_segments\"]             \n",
    "                frj= frj+1     \n",
    "                for tsi in range (0, nts_qtrib_g):\n",
    "                    t_min=  dt_qtrib_g/60.0*float(tsi)                        \n",
    "                    dmy1= qtrib_g[tsi, frj]\n",
    "                    pyqtrib.write(\"%s %s %s\\n\" %\\\n",
    "                                 (str(frj+1), str(t_min), str(dmy1)) )  \n",
    "                                 # <- +1 is added to frj for accommodating Fortran indexing.      \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    #                              Step 0-10\n",
    "\n",
    "    #                 Prepare cross section bathymetry data\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    \n",
    "    x_bathy_g, z_bathy_g, size_bathy_g, mxnbathy_g = fp_naturalxsec_map(        \n",
    "                                                                mainstem_headseg_list, \n",
    "                                                                inland_bathyNC, \n",
    "                                                                comid_bathy, \n",
    "                                                                geo_index, \n",
    "                                                                geo_cols, \n",
    "                                                                geo_data, \n",
    "                                                                mxncomp_g, \n",
    "                                                                nrch_g)\n",
    "    \n",
    "    # TODO: Call uniform flow lookup table creation kernel    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    #                              Step 0-11\n",
    "\n",
    "    #                       Build input dictionary\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    ntss_ev_g = int((tfin_g - t0_g) * 3600.0 / dt) + 1\n",
    "\n",
    "    # build a dictionary of diffusive model inputs and helper variables\n",
    "    diff_ins = {}\n",
    "\n",
    "    # model input parameters\n",
    "        # model input parameters\n",
    "    diff_ins[\"timestep_ar_g\"]= timestep_ar_g  \n",
    "    diff_ins[\"nts_ql_g\"] = nts_ql_g\n",
    "    diff_ins[\"nts_ub_g\"] = nts_ub_g\n",
    "    diff_ins[\"nts_db_g\"] = nts_db_g\n",
    "    diff_ins[\"ntss_ev_g\"] = ntss_ev_g\n",
    "    \n",
    "    diff_ins[\"nts_qtrib_g\"] = nts_qtrib_g\n",
    "    \n",
    "    diff_ins[\"mxncomp_g\"] = mxncomp_g\n",
    "    diff_ins[\"nrch_g\"] = nrch_g\n",
    "    diff_ins[\"z_ar_g\"] = z_ar_g\n",
    "    diff_ins[\"bo_ar_g\"] = bo_ar_g\n",
    "    diff_ins[\"traps_ar_g\"] = traps_ar_g\n",
    "    diff_ins[\"tw_ar_g\"] = tw_ar_g\n",
    "    diff_ins[\"twcc_ar_g\"] = twcc_ar_g\n",
    "    diff_ins[\"mann_ar_g\"] = mann_ar_g\n",
    "    diff_ins[\"manncc_ar_g\"] = manncc_ar_g\n",
    "    diff_ins[\"so_ar_g\"] = so_ar_g\n",
    "    diff_ins[\"dx_ar_g\"] = dx_ar_g\n",
    "    diff_ins[\"frnw_col\"] = frnw_col\n",
    "    diff_ins[\"frnw_g\"] = dfrnw_g\n",
    "    diff_ins[\"qlat_g\"] = qlat_g\n",
    "    diff_ins[\"ubcd_g\"] = ubcd_g\n",
    "    diff_ins[\"dbcd_g\"] = dbcd_g\n",
    "    \n",
    "    diff_ins[\"qtrib_g\"] = qtrib_g\n",
    "    \n",
    "    diff_ins[\"paradim\"] = paradim \n",
    "    diff_ins[\"para_ar_g\"] = para_ar_g   \n",
    "    diff_ins[\"iniq\"] = iniq\n",
    "    # python-fortran crosswalk data\n",
    "    diff_ins[\"pynw\"] = pynw\n",
    "    diff_ins[\"ordered_reaches\"] = ordered_reaches\n",
    "    # bathymetry data\n",
    "    diff_ins[\"x_bathy_g\"]= x_bathy_g\n",
    "    diff_ins[\"z_bathy_g\"]= z_bathy_g\n",
    "    diff_ins[\"size_bathy_g\"]= size_bathy_g\n",
    "    diff_ins[\"mxnbathy_g\"]= mxnbathy_g\n",
    "\n",
    "    \n",
    "    \n",
    "    '''    \n",
    "    diff_ins[\"dtini_g\"] = dtini_g\n",
    "    diff_ins[\"t0_g\"] = t0_g\n",
    "    diff_ins[\"tfin_g\"] = tfin_g\n",
    "    diff_ins[\"saveinterval_tu\"] = saveinterval_tu\n",
    "    diff_ins[\"saveinterval_cnt\"] = saveinterval_cnt\n",
    "    diff_ins[\"dt_ql_g\"] = dt_ql_g\n",
    "    diff_ins[\"dt_ub_g\"] = dt_ub_g\n",
    "    diff_ins[\"dt_db_g\"] = dt_db_g\n",
    "    diff_ins[\"nts_ql_g\"] = nts_ql_g\n",
    "    diff_ins[\"nts_ub_g\"] = nts_ub_g\n",
    "    diff_ins[\"nts_db_g\"] = nts_db_g\n",
    "    diff_ins[\"mxncomp_g\"] = mxncomp_g\n",
    "    diff_ins[\"nrch_g\"] = nrch_g\n",
    "    diff_ins[\"z_ar_g\"] = z_ar_g\n",
    "    diff_ins[\"bo_ar_g\"] = bo_ar_g\n",
    "    diff_ins[\"traps_ar_g\"] = traps_ar_g\n",
    "    diff_ins[\"tw_ar_g\"] = tw_ar_g\n",
    "    diff_ins[\"twcc_ar_g\"] = twcc_ar_g\n",
    "    diff_ins[\"mann_ar_g\"] = mann_ar_g\n",
    "    diff_ins[\"manncc_ar_g\"] = manncc_ar_g\n",
    "    diff_ins[\"so_ar_g\"] = so_ar_g\n",
    "    diff_ins[\"dx_ar_g\"] = dx_ar_g\n",
    "    #diff_ins[\"nhincr_m_g\"] = nhincr_m_g\n",
    "    #diff_ins[\"nhincr_f_g\"] = nhincr_f_g\n",
    "    #diff_ins[\"ufhlt_m_g\"] = ufhlt_m_g\n",
    "    #diff_ins[\"ufqlt_m_g\"] = ufqlt_m_g\n",
    "    #diff_ins[\"ufhlt_f_g\"] = ufhlt_f_g\n",
    "    #diff_ins[\"ufqlt_f_g\"] = ufqlt_f_g\n",
    "    diff_ins[\"frnw_col\"] = frnw_col\n",
    "    diff_ins[\"frnw_g\"] = dfrnw_g\n",
    "    diff_ins[\"qlat_g\"] = qlat_g\n",
    "    diff_ins[\"ubcd_g\"] = ubcd_g\n",
    "    diff_ins[\"dbcd_g\"] = dbcd_g\n",
    "    diff_ins[\"cfl_g\"] = cfl_g\n",
    "    diff_ins[\"theta_g\"] = theta_g\n",
    "    diff_ins[\"tzeq_flag_g\"] = tzeq_flag_g\n",
    "    diff_ins[\"y_opt_g\"] = y_opt_g\n",
    "    diff_ins[\"so_llm_g\"] = so_llm_g\n",
    "    diff_ins[\"ntss_ev_g\"] = ntss_ev_g\n",
    "    diff_ins[\"iniq\"] = iniq\n",
    "\n",
    "    # python-fortran crosswalk data\n",
    "    diff_ins[\"pynw\"] = pynw\n",
    "    diff_ins[\"ordered_reaches\"] = ordered_reaches    \n",
    "    '''\n",
    "    #import pdb; pdb.set_trace()\n",
    "    \n",
    "    return diff_ins\n",
    "\n",
    "\n",
    "def unpack_output(pynw, ordered_reaches, out_q, out_elv):\n",
    "    \"\"\"\n",
    "    Unpack diffusive wave output arrays\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pynw -- (dict) ordered reach head segments\n",
    "    ordered_reaches -- \n",
    "    out_q -- (diffusive._memoryviewslice of float64) diffusive wave model flow output (m3/sec)\n",
    "    out_elv -- (diffusive._memoryviewslice of float64) diffusive wave model water surface elevation output (meters)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.asarray(rch_list, dtype=np.intp) - segment indices \n",
    "    np.asarray(dat_all, dtype = 'float32') - flow, velocity, elevation array\n",
    "    \"\"\"\n",
    "\n",
    "    reach_heads = list(pynw.values())\n",
    "    nts = len(out_q[:, 0, 0])\n",
    "\n",
    "    i = 1\n",
    "    rch_list = []\n",
    "    for o in ordered_reaches.keys():\n",
    "        for rch in ordered_reaches[o]:\n",
    "\n",
    "            rch_segs = rch[1][\"segments_list\"]\n",
    "            rch_list.extend(rch_segs[:-1])\n",
    "\n",
    "            j = reach_heads.index(rch[0])\n",
    "\n",
    "            if i == 1:\n",
    "                dat_all = np.empty((len(rch_segs)-1, nts * 3))\n",
    "                dat_all[:] = np.nan\n",
    "                # flow result\n",
    "                dat_all[:, ::3] = np.transpose(np.array(out_q[:, 1 : len(rch_segs), j]))\n",
    "                # elevation result\n",
    "                dat_all[:, 2::3] = np.transpose(\n",
    "                    np.array(out_elv[:, 1 : len(rch_segs), j])\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                dat_all_c = np.empty((len(rch_segs)-1, nts * 3))\n",
    "                dat_all_c[:] = np.nan\n",
    "                # flow result\n",
    "                dat_all_c[:, ::3] = np.transpose(\n",
    "                    np.array(out_q[:, 1 : len(rch_segs), j])\n",
    "                )\n",
    "                # elevation result\n",
    "                dat_all_c[:, 2::3] = np.transpose(\n",
    "                    np.array(out_elv[:, 1 : len(rch_segs), j])\n",
    "                )\n",
    "                # concatenate\n",
    "                dat_all = np.concatenate((dat_all, dat_all_c))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    return np.asarray(rch_list, dtype=np.intp), np.asarray(dat_all, dtype=\"float32\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
